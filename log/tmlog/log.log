-INFO-2021/11/04 18:29:11,899-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.252:18108, 10.0.12.253:18108, 10.0.12.254:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 18:29:12,033-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 18:29:12,033-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-WARN-2021/11/04 18:29:13,526-org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.handleCompletedMetadataResponse(NetworkClient.java:846)-846-Error while fetching metadata with correlation id 2 : {r_source=LEADER_NOT_AVAILABLE}
-WARN-2021/11/04 18:29:14,575-org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.handleCompletedMetadataResponse(NetworkClient.java:846)-846-Error while fetching metadata with correlation id 7 : {r_source=LEADER_NOT_AVAILABLE}
-WARN-2021/11/04 18:29:14,709-org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.handleCompletedMetadataResponse(NetworkClient.java:846)-846-Error while fetching metadata with correlation id 8 : {r_source=LEADER_NOT_AVAILABLE}
-WARN-2021/11/04 18:29:14,837-org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.handleCompletedMetadataResponse(NetworkClient.java:846)-846-Error while fetching metadata with correlation id 9 : {r_source=LEADER_NOT_AVAILABLE}
-WARN-2021/11/04 18:29:14,967-org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.handleCompletedMetadataResponse(NetworkClient.java:846)-846-Error while fetching metadata with correlation id 10 : {r_source=LEADER_NOT_AVAILABLE}
-INFO-2021/11/04 18:30:31,310-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.252:18108, 10.0.12.253:18108, 10.0.12.254:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 18:30:31,439-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 18:30:31,439-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/04 18:30:47,085-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.252:18108, 10.0.12.253:18108, 10.0.12.254:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 18:30:47,214-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 18:30:47,215-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/04 18:31:16,260-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.252:18108, 10.0.12.253:18108, 10.0.12.254:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 18:31:16,368-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 18:31:16,369-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/04 18:31:37,453-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.252:18108, 10.0.12.253:18108, 10.0.12.254:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 18:31:37,564-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 18:31:37,564-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/04 18:31:58,300-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 18:31:58,427-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 18:31:58,427-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/04 18:33:02,197-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 18:33:02,320-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 18:33:02,321-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/04 18:33:05,846-org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1017)-1017-Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
-INFO-2021/11/04 18:33:29,884-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 18:33:30,004-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 18:33:30,004-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/04 18:38:29,279-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 18:38:29,398-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 18:38:29,398-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/04 18:39:00,314-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 18:39:00,428-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 18:39:00,429-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/04 18:40:48,718-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 18:40:48,847-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 18:40:48,848-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/04 18:47:11,722-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 18:47:11,840-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 18:47:11,841-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/04 18:50:34,390-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 18:50:34,532-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 18:50:34,532-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/04 18:56:30,495-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 18:56:30,625-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 18:56:30,625-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/04 19:40:14,069-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 19:40:14,213-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 19:40:14,215-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/04 19:51:35,353-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 19:51:35,513-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 19:51:35,514-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/04 20:00:09,636-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/04 20:00:09,781-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/04 20:00:09,781-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 09:37:21,875-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 09:37:22,011-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 09:37:22,012-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 09:38:09,645-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 09:38:09,774-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 09:38:09,774-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:12:14,750-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.cpu.cores' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 1.7976931348623157E308
-INFO-2021/11/05 11:12:14,755-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.memory.task.heap.size' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
-INFO-2021/11/05 11:12:14,756-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.memory.task.off-heap.size' , default: 0 bytes (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
-INFO-2021/11/05 11:12:14,756-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.memory.network.min' , default: 64 mb (fallback keys: [{key=taskmanager.network.memory.min, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
-INFO-2021/11/05 11:12:14,757-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.memory.network.max' , default: 1 gb (fallback keys: [{key=taskmanager.network.memory.max, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
-INFO-2021/11/05 11:12:14,757-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.memory.managed.size' , default: null (fallback keys: [{key=taskmanager.memory.size, isDeprecated=true}]) required for local execution is not set, setting it to its default value 128 mb
-INFO-2021/11/05 11:12:14,776-org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:251)-251-Starting Flink Mini Cluster
-INFO-2021/11/05 11:12:14,778-org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:260)-260-Starting Metrics Registry
-INFO-2021/11/05 11:12:14,822-org.apache.flink.runtime.metrics.MetricRegistryImpl.<init>(MetricRegistryImpl.java:115)-115-No metrics reporter configured, no metrics will be exposed/reported.
-INFO-2021/11/05 11:12:14,823-org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:264)-264-Starting RPC Service(s)
-INFO-2021/11/05 11:12:14,945-org.apache.flink.runtime.clusterframework.BootstrapTools.startLocalActorSystem(BootstrapTools.java:247)-247-Trying to start local actor system
-INFO-2021/11/05 11:12:15,399-akka.event.slf4j.Slf4jLogger$$anonfun$receive$1.applyOrElse(Slf4jLogger.scala:92)-92-Slf4jLogger started
-INFO-2021/11/05 11:12:15,817-org.apache.flink.runtime.clusterframework.BootstrapTools.startActorSystem(BootstrapTools.java:278)-278-Actor system started at akka://flink
-INFO-2021/11/05 11:12:15,828-org.apache.flink.runtime.clusterframework.BootstrapTools.startLocalActorSystem(BootstrapTools.java:247)-247-Trying to start local actor system
-INFO-2021/11/05 11:12:15,840-akka.event.slf4j.Slf4jLogger$$anonfun$receive$1.applyOrElse(Slf4jLogger.scala:92)-92-Slf4jLogger started
-INFO-2021/11/05 11:12:15,900-org.apache.flink.runtime.clusterframework.BootstrapTools.startActorSystem(BootstrapTools.java:278)-278-Actor system started at akka://flink-metrics
-INFO-2021/11/05 11:12:15,914-org.apache.flink.runtime.rpc.akka.AkkaRpcService.startServer(AkkaRpcService.java:225)-225-Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
-INFO-2021/11/05 11:12:16,008-org.apache.flink.runtime.minicluster.MiniCluster.createHighAvailabilityServices(MiniCluster.java:432)-432-Starting high-availability services
-INFO-2021/11/05 11:12:16,023-org.apache.flink.runtime.blob.BlobServer.<init>(BlobServer.java:143)-143-Created BLOB server storage directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/blobStore-14258a68-e632-412b-9ac6-dd10bd83c614
-INFO-2021/11/05 11:12:16,032-org.apache.flink.runtime.blob.BlobServer.<init>(BlobServer.java:207)-207-Started BLOB server at 0.0.0.0:64079 - max concurrent requests: 50 - max backlog: 1000
-INFO-2021/11/05 11:12:16,040-org.apache.flink.runtime.blob.AbstractBlobCache.<init>(AbstractBlobCache.java:107)-107-Created BLOB cache storage directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/blobStore-cb11d5c2-ddc7-40ab-b7f1-df8a7d9597cf
-INFO-2021/11/05 11:12:16,043-org.apache.flink.runtime.blob.AbstractBlobCache.<init>(AbstractBlobCache.java:107)-107-Created BLOB cache storage directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/blobStore-96a599e5-d45a-4b9d-90a9-74f81a774245
-INFO-2021/11/05 11:12:16,043-org.apache.flink.runtime.minicluster.MiniCluster.startTaskManagers(MiniCluster.java:519)-519-Starting 1 TaskManger(s)
-INFO-2021/11/05 11:12:16,046-org.apache.flink.runtime.taskexecutor.TaskManagerRunner.startTaskManager(TaskManagerRunner.java:351)-351-Starting TaskManager with ResourceID: 4c28151b-d044-4360-802a-4e8cfbbf7d6f
-INFO-2021/11/05 11:12:16,081-org.apache.flink.runtime.taskexecutor.TaskManagerServices.checkTempDirs(TaskManagerServices.java:405)-405-Temporary file directory '/var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T': total 465 GB, usable 330 GB (70.97% usable)
-INFO-2021/11/05 11:12:16,084-org.apache.flink.runtime.io.disk.FileChannelManagerImpl.createFiles(FileChannelManagerImpl.java:97)-97-FileChannelManager uses directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-io-ea608257-a8dd-4d4d-84d4-f8f80325ab02 for spill files.
-INFO-2021/11/05 11:12:16,094-org.apache.flink.runtime.io.disk.FileChannelManagerImpl.createFiles(FileChannelManagerImpl.java:97)-97-FileChannelManager uses directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-netty-shuffle-9449fc1b-6d5f-46e1-9e92-1b44b01d9d01 for spill files.
-INFO-2021/11/05 11:12:16,144-org.apache.flink.runtime.io.network.buffer.NetworkBufferPool.<init>(NetworkBufferPool.java:145)-145-Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
-INFO-2021/11/05 11:12:16,150-org.apache.flink.runtime.io.network.NettyShuffleEnvironment.start(NettyShuffleEnvironment.java:293)-293-Starting the network environment and its components.
-INFO-2021/11/05 11:12:16,152-org.apache.flink.runtime.taskexecutor.KvStateService.start(KvStateService.java:89)-89-Starting the kvState service and its components.
-INFO-2021/11/05 11:12:16,171-org.apache.flink.runtime.rpc.akka.AkkaRpcService.startServer(AkkaRpcService.java:225)-225-Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
-INFO-2021/11/05 11:12:16,183-org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService.start(DefaultJobLeaderService.java:116)-116-Start job leader service.
-INFO-2021/11/05 11:12:16,184-org.apache.flink.runtime.filecache.FileCache.<init>(FileCache.java:107)-107-User file cache uses directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-dist-cache-2cacb5af-2163-42f3-b9cb-49eb8d0ee281
-INFO-2021/11/05 11:12:16,219-org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:140)-140-Starting rest endpoint.
-WARN-2021/11/05 11:12:16,421-org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation.find(WebMonitorUtils.java:91)-91-Log file environment variable 'log.file' is not set.
-WARN-2021/11/05 11:12:16,421-org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation.find(WebMonitorUtils.java:97)-97-JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
-INFO-2021/11/05 11:12:16,608-org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:236)-236-Rest endpoint listening at localhost:64137
-INFO-2021/11/05 11:12:16,609-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.updateLeader(EmbeddedLeaderService.java:302)-302-Proposing leadership to contender http://localhost:64137
-INFO-2021/11/05 11:12:16,612-org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.startInternal(WebMonitorEndpoint.java:756)-756-Web frontend listening at http://localhost:64137.
-INFO-2021/11/05 11:12:16,612-org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.grantLeadership(WebMonitorEndpoint.java:812)-812-http://localhost:64137 was granted leadership with leaderSessionID=24c57211-e3cf-4ba2-9d6e-2baadc59ba69
-INFO-2021/11/05 11:12:16,612-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.confirmLeader(EmbeddedLeaderService.java:252)-252-Received confirmation of leadership for leader http://localhost:64137 , session=24c57211-e3cf-4ba2-9d6e-2baadc59ba69
-INFO-2021/11/05 11:12:16,625-org.apache.flink.runtime.rpc.akka.AkkaRpcService.startServer(AkkaRpcService.java:225)-225-Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
-INFO-2021/11/05 11:12:16,642-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.updateLeader(EmbeddedLeaderService.java:302)-302-Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
-INFO-2021/11/05 11:12:16,642-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.updateLeader(EmbeddedLeaderService.java:302)-302-Proposing leadership to contender LeaderContender: StandaloneResourceManager
-INFO-2021/11/05 11:12:16,644-org.apache.flink.runtime.resourcemanager.ResourceManager.tryAcceptLeadership(ResourceManager.java:984)-984-ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token b3e317192f1f3554e741bd83609549d4
-INFO-2021/11/05 11:12:16,645-org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:372)-372-Flink Mini Cluster started successfully
-INFO-2021/11/05 11:12:16,649-org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl.start(SlotManagerImpl.java:279)-279-Starting the SlotManager.
-INFO-2021/11/05 11:12:16,650-org.apache.flink.runtime.dispatcher.runner.AbstractDispatcherLeaderProcess.startInternal(AbstractDispatcherLeaderProcess.java:101)-101-Start SessionDispatcherLeaderProcess.
-INFO-2021/11/05 11:12:16,652-org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess.recoverJobs(SessionDispatcherLeaderProcess.java:120)-120-Recover all persisted job graphs.
-INFO-2021/11/05 11:12:16,652-org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess.recoverJobs(SessionDispatcherLeaderProcess.java:128)-128-Successfully recovered 0 persisted job graphs.
-INFO-2021/11/05 11:12:16,654-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.confirmLeader(EmbeddedLeaderService.java:252)-252-Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=e741bd83-6095-49d4-b3e3-17192f1f3554
-INFO-2021/11/05 11:12:16,656-org.apache.flink.runtime.taskexecutor.TaskExecutor.connectToResourceManager(TaskExecutor.java:1123)-1123-Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b3e317192f1f3554e741bd83609549d4).
-INFO-2021/11/05 11:12:16,660-org.apache.flink.runtime.rpc.akka.AkkaRpcService.startServer(AkkaRpcService.java:225)-225-Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
-INFO-2021/11/05 11:12:16,671-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.confirmLeader(EmbeddedLeaderService.java:252)-252-Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=8ccaed65-526b-4f0d-b193-d36e120a257c
-INFO-2021/11/05 11:12:16,677-org.apache.flink.runtime.registration.RetryingRegistration.lambda$startRegistration$0(RetryingRegistration.java:155)-155-Resolved ResourceManager address, beginning registration
-INFO-2021/11/05 11:12:16,686-org.apache.flink.runtime.resourcemanager.ResourceManager.registerTaskExecutorInternal(ResourceManager.java:781)-781-Registering TaskManager with ResourceID 4c28151b-d044-4360-802a-4e8cfbbf7d6f (akka://flink/user/rpc/taskmanager_0) at ResourceManager
-INFO-2021/11/05 11:12:16,688-org.apache.flink.runtime.dispatcher.Dispatcher.submitJob(Dispatcher.java:275)-275-Received JobGraph submission b01dceda6fcbf8d652fb05aa6cb635a5 (this is kafka_test).
-INFO-2021/11/05 11:12:16,688-org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection.onRegistrationSuccess(TaskExecutorToResourceManagerConnection.java:84)-84-Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id b44276635c7c391a7431a0dd3e8d7a1d.
-INFO-2021/11/05 11:12:16,689-org.apache.flink.runtime.dispatcher.Dispatcher.internalSubmitJob(Dispatcher.java:332)-332-Submitting job b01dceda6fcbf8d652fb05aa6cb635a5 (this is kafka_test).
-INFO-2021/11/05 11:12:16,716-org.apache.flink.runtime.rpc.akka.AkkaRpcService.startServer(AkkaRpcService.java:225)-225-Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
-INFO-2021/11/05 11:12:16,728-org.apache.flink.runtime.jobmaster.JobMaster.<init>(JobMaster.java:248)-248-Initializing job this is kafka_test (b01dceda6fcbf8d652fb05aa6cb635a5).
-INFO-2021/11/05 11:12:16,745-org.apache.flink.runtime.scheduler.DefaultSchedulerFactory.createInstance(DefaultSchedulerFactory.java:80)-80-Using restart back off time strategy NoRestartBackoffTimeStrategy for this is kafka_test (b01dceda6fcbf8d652fb05aa6cb635a5).
-INFO-2021/11/05 11:12:16,878-org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder.buildGraph(ExecutionGraphBuilder.java:202)-202-Running initialization on master for job this is kafka_test (b01dceda6fcbf8d652fb05aa6cb635a5).
-INFO-2021/11/05 11:12:16,878-org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder.buildGraph(ExecutionGraphBuilder.java:220)-220-Successfully ran initialization on master in 0 ms.
-INFO-2021/11/05 11:12:16,896-org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology.initializePipelinedRegions(DefaultExecutionTopology.java:111)-111-Built 8 pipelined regions in 0 ms
-INFO-2021/11/05 11:12:16,907-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:12:16,921-org.apache.flink.runtime.scheduler.DefaultScheduler.<init>(DefaultScheduler.java:148)-148-Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@438840a7 for this is kafka_test (b01dceda6fcbf8d652fb05aa6cb635a5).
-INFO-2021/11/05 11:12:16,924-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.updateLeader(EmbeddedLeaderService.java:302)-302-Proposing leadership to contender akka://flink/user/rpc/jobmanager_3
-INFO-2021/11/05 11:12:16,925-org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl.startJobMaster(JobManagerRunnerImpl.java:304)-304-JobManager runner for job this is kafka_test (b01dceda6fcbf8d652fb05aa6cb635a5) was granted leadership with session id 88ab4892-1474-4db9-b12f-653b0cbbaca9 at akka://flink/user/rpc/jobmanager_3.
-INFO-2021/11/05 11:12:16,930-org.apache.flink.runtime.jobmaster.JobMaster.startJobExecution(JobMaster.java:758)-758-Starting execution of job this is kafka_test (b01dceda6fcbf8d652fb05aa6cb635a5) under job master id b12f653b0cbbaca988ab489214744db9.
-INFO-2021/11/05 11:12:16,931-org.apache.flink.runtime.scheduler.DefaultScheduler.startSchedulingInternal(DefaultScheduler.java:171)-171-Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.EagerSchedulingStrategy]
-INFO-2021/11/05 11:12:16,932-org.apache.flink.runtime.executiongraph.ExecutionGraph.transitionState(ExecutionGraph.java:1240)-1240-Job this is kafka_test (b01dceda6fcbf8d652fb05aa6cb635a5) switched from state CREATED to RUNNING.
-INFO-2021/11/05 11:12:16,939-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (1/8) (6eb90fb630b31d10a88c4107c4d4111b) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:12:16,939-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (2/8) (60de1add9d70fe4dbbd89c0fb3457988) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:12:16,939-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (3/8) (74228519ed9557992d05bcb15e97486e) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:12:16,939-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (4/8) (2528ad0fef5ac1fe2826623449be3178) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:12:16,940-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (5/8) (9ced5e992c312db477a02b37a38f63fb) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:12:16,940-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (6/8) (4adc68d7b4c7c0a2dbf9ebe99afdf712) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:12:16,940-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (7/8) (db50018cf1f799246f7cb37214807409) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:12:16,940-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (8/8) (fa5289ab3851790fe0db34afa95a22fe) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:12:16,951-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{7959e8122135439ce5326d393e5b6d0c}]
-INFO-2021/11/05 11:12:16,955-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{4384592c2410131093628ee9b9a5be6b}]
-INFO-2021/11/05 11:12:16,956-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{28d57ecfcbf958c6192a4eee2c46fba7}]
-INFO-2021/11/05 11:12:16,956-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{64ed3b5132a446ec075f5010160d0a01}]
-INFO-2021/11/05 11:12:16,956-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{5decbfa0cdead02576ea981d2ec748ea}]
-INFO-2021/11/05 11:12:16,957-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{44fb0ccbbade3154cab083b9f1f10eae}]
-INFO-2021/11/05 11:12:16,957-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{ebf67cb2508711a8bb393384c53f455c}]
-INFO-2021/11/05 11:12:16,957-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f4a8ae04f35564e868b42e705cdb33f8}]
-INFO-2021/11/05 11:12:16,959-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.confirmLeader(EmbeddedLeaderService.java:252)-252-Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=88ab4892-1474-4db9-b12f-653b0cbbaca9
-INFO-2021/11/05 11:12:16,959-org.apache.flink.runtime.jobmaster.JobMaster.connectToResourceManager(JobMaster.java:984)-984-Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b3e317192f1f3554e741bd83609549d4)
-INFO-2021/11/05 11:12:16,961-org.apache.flink.runtime.registration.RetryingRegistration.lambda$startRegistration$0(RetryingRegistration.java:155)-155-Resolved ResourceManager address, beginning registration
-INFO-2021/11/05 11:12:16,963-org.apache.flink.runtime.resourcemanager.ResourceManager.registerJobManager(ResourceManager.java:317)-317-Registering job manager b12f653b0cbbaca988ab489214744db9@akka://flink/user/rpc/jobmanager_3 for job b01dceda6fcbf8d652fb05aa6cb635a5.
-INFO-2021/11/05 11:12:16,967-org.apache.flink.runtime.resourcemanager.ResourceManager.registerJobMasterInternal(ResourceManager.java:727)-727-Registered job manager b12f653b0cbbaca988ab489214744db9@akka://flink/user/rpc/jobmanager_3 for job b01dceda6fcbf8d652fb05aa6cb635a5.
-INFO-2021/11/05 11:12:16,968-org.apache.flink.runtime.jobmaster.JobMaster.establishResourceManagerConnection(JobMaster.java:1006)-1006-JobManager successfully registered at ResourceManager, leader id: b3e317192f1f3554e741bd83609549d4.
-INFO-2021/11/05 11:12:16,969-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{7959e8122135439ce5326d393e5b6d0c}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:12:16,970-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job b01dceda6fcbf8d652fb05aa6cb635a5 with allocation id 7c92e9cfb0f734659f932f7e1715abfc.
-INFO-2021/11/05 11:12:16,970-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{4384592c2410131093628ee9b9a5be6b}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:12:16,971-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{28d57ecfcbf958c6192a4eee2c46fba7}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:12:16,971-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{64ed3b5132a446ec075f5010160d0a01}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:12:16,971-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{5decbfa0cdead02576ea981d2ec748ea}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:12:16,972-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{44fb0ccbbade3154cab083b9f1f10eae}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:12:16,972-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{ebf67cb2508711a8bb393384c53f455c}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:12:16,972-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{f4a8ae04f35564e868b42e705cdb33f8}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:12:16,973-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 7c92e9cfb0f734659f932f7e1715abfc for job b01dceda6fcbf8d652fb05aa6cb635a5 from resource manager with leader id b3e317192f1f3554e741bd83609549d4.
-INFO-2021/11/05 11:12:16,974-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job b01dceda6fcbf8d652fb05aa6cb635a5 with allocation id c8936f8296087c0165b5355a4fb6bfe5.
-INFO-2021/11/05 11:12:16,975-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job b01dceda6fcbf8d652fb05aa6cb635a5 with allocation id 240639885a5ffe47701c787356492976.
-INFO-2021/11/05 11:12:16,975-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job b01dceda6fcbf8d652fb05aa6cb635a5 with allocation id a80c2bed45d2918c32f67fb72f698ee5.
-INFO-2021/11/05 11:12:16,976-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job b01dceda6fcbf8d652fb05aa6cb635a5 with allocation id 1b6a8674322befce9b6783eee074b28d.
-INFO-2021/11/05 11:12:16,976-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job b01dceda6fcbf8d652fb05aa6cb635a5 with allocation id 8ebfe2a73c74dd3c8ab36def244e6711.
-INFO-2021/11/05 11:12:16,977-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job b01dceda6fcbf8d652fb05aa6cb635a5 with allocation id 5dc27f2f8d96b2fb173c0408f36121c6.
-INFO-2021/11/05 11:12:16,978-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job b01dceda6fcbf8d652fb05aa6cb635a5 with allocation id 60c76c6653665227ec2ffac20819cf52.
-INFO-2021/11/05 11:12:16,979-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 7c92e9cfb0f734659f932f7e1715abfc.
-INFO-2021/11/05 11:12:16,980-org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService.addJob(DefaultJobLeaderService.java:172)-172-Add job b01dceda6fcbf8d652fb05aa6cb635a5 for job leader monitoring.
-INFO-2021/11/05 11:12:16,981-org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener.openRpcConnectionTo(DefaultJobLeaderService.java:314)-314-Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id 88ab4892-1474-4db9-b12f-653b0cbbaca9.
-INFO-2021/11/05 11:12:16,982-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request c8936f8296087c0165b5355a4fb6bfe5 for job b01dceda6fcbf8d652fb05aa6cb635a5 from resource manager with leader id b3e317192f1f3554e741bd83609549d4.
-INFO-2021/11/05 11:12:16,982-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for c8936f8296087c0165b5355a4fb6bfe5.
-INFO-2021/11/05 11:12:16,982-org.apache.flink.runtime.registration.RetryingRegistration.lambda$startRegistration$0(RetryingRegistration.java:155)-155-Resolved JobManager address, beginning registration
-INFO-2021/11/05 11:12:16,983-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 240639885a5ffe47701c787356492976 for job b01dceda6fcbf8d652fb05aa6cb635a5 from resource manager with leader id b3e317192f1f3554e741bd83609549d4.
-INFO-2021/11/05 11:12:16,983-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 240639885a5ffe47701c787356492976.
-INFO-2021/11/05 11:12:16,984-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request a80c2bed45d2918c32f67fb72f698ee5 for job b01dceda6fcbf8d652fb05aa6cb635a5 from resource manager with leader id b3e317192f1f3554e741bd83609549d4.
-INFO-2021/11/05 11:12:16,984-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for a80c2bed45d2918c32f67fb72f698ee5.
-INFO-2021/11/05 11:12:16,984-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 1b6a8674322befce9b6783eee074b28d for job b01dceda6fcbf8d652fb05aa6cb635a5 from resource manager with leader id b3e317192f1f3554e741bd83609549d4.
-INFO-2021/11/05 11:12:16,985-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 1b6a8674322befce9b6783eee074b28d.
-INFO-2021/11/05 11:12:16,985-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 8ebfe2a73c74dd3c8ab36def244e6711 for job b01dceda6fcbf8d652fb05aa6cb635a5 from resource manager with leader id b3e317192f1f3554e741bd83609549d4.
-INFO-2021/11/05 11:12:16,985-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 8ebfe2a73c74dd3c8ab36def244e6711.
-INFO-2021/11/05 11:12:16,986-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 5dc27f2f8d96b2fb173c0408f36121c6 for job b01dceda6fcbf8d652fb05aa6cb635a5 from resource manager with leader id b3e317192f1f3554e741bd83609549d4.
-INFO-2021/11/05 11:12:16,986-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 5dc27f2f8d96b2fb173c0408f36121c6.
-INFO-2021/11/05 11:12:16,986-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 60c76c6653665227ec2ffac20819cf52 for job b01dceda6fcbf8d652fb05aa6cb635a5 from resource manager with leader id b3e317192f1f3554e741bd83609549d4.
-INFO-2021/11/05 11:12:16,987-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 60c76c6653665227ec2ffac20819cf52.
-INFO-2021/11/05 11:12:16,988-org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection.onRegistrationSuccess(DefaultJobLeaderService.java:369)-369-Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job b01dceda6fcbf8d652fb05aa6cb635a5.
-INFO-2021/11/05 11:12:16,989-org.apache.flink.runtime.taskexecutor.TaskExecutor.establishJobManagerConnection(TaskExecutor.java:1372)-1372-Establish JobManager connection for job b01dceda6fcbf8d652fb05aa6cb635a5.
-INFO-2021/11/05 11:12:16,992-org.apache.flink.runtime.taskexecutor.TaskExecutor.internalOfferSlotsToJobManager(TaskExecutor.java:1271)-1271-Offer reserved slots to the leader of job b01dceda6fcbf8d652fb05aa6cb635a5.
-INFO-2021/11/05 11:12:16,998-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (1/8) (6eb90fb630b31d10a88c4107c4d4111b) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:12:16,998-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (1/8) (attempt #0) to 4c28151b-d044-4360-802a-4e8cfbbf7d6f @ localhost (dataPort=-1)
-INFO-2021/11/05 11:12:17,003-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (2/8) (60de1add9d70fe4dbbd89c0fb3457988) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:12:17,003-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (2/8) (attempt #0) to 4c28151b-d044-4360-802a-4e8cfbbf7d6f @ localhost (dataPort=-1)
-INFO-2021/11/05 11:12:17,003-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 7c92e9cfb0f734659f932f7e1715abfc.
-INFO-2021/11/05 11:12:17,004-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (3/8) (74228519ed9557992d05bcb15e97486e) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:12:17,004-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (3/8) (attempt #0) to 4c28151b-d044-4360-802a-4e8cfbbf7d6f @ localhost (dataPort=-1)
-INFO-2021/11/05 11:12:17,004-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (4/8) (2528ad0fef5ac1fe2826623449be3178) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:12:17,005-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (4/8) (attempt #0) to 4c28151b-d044-4360-802a-4e8cfbbf7d6f @ localhost (dataPort=-1)
-INFO-2021/11/05 11:12:17,005-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (5/8) (9ced5e992c312db477a02b37a38f63fb) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:12:17,005-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (5/8) (attempt #0) to 4c28151b-d044-4360-802a-4e8cfbbf7d6f @ localhost (dataPort=-1)
-INFO-2021/11/05 11:12:17,006-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (6/8) (4adc68d7b4c7c0a2dbf9ebe99afdf712) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:12:17,006-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (6/8) (attempt #0) to 4c28151b-d044-4360-802a-4e8cfbbf7d6f @ localhost (dataPort=-1)
-INFO-2021/11/05 11:12:17,006-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (7/8) (db50018cf1f799246f7cb37214807409) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:12:17,006-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (7/8) (attempt #0) to 4c28151b-d044-4360-802a-4e8cfbbf7d6f @ localhost (dataPort=-1)
-INFO-2021/11/05 11:12:17,007-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (8/8) (fa5289ab3851790fe0db34afa95a22fe) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:12:17,007-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (8/8) (attempt #0) to 4c28151b-d044-4360-802a-4e8cfbbf7d6f @ localhost (dataPort=-1)
-INFO-2021/11/05 11:12:17,026-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (1/8).
-INFO-2021/11/05 11:12:17,027-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (1/8) (6eb90fb630b31d10a88c4107c4d4111b) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:12:17,028-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot c8936f8296087c0165b5355a4fb6bfe5.
-INFO-2021/11/05 11:12:17,030-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (1/8) (6eb90fb630b31d10a88c4107c4d4111b) [DEPLOYING].
-INFO-2021/11/05 11:12:17,031-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (2/8).
-INFO-2021/11/05 11:12:17,031-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (2/8) (60de1add9d70fe4dbbd89c0fb3457988) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:12:17,031-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 240639885a5ffe47701c787356492976.
-INFO-2021/11/05 11:12:17,032-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (2/8) (60de1add9d70fe4dbbd89c0fb3457988) [DEPLOYING].
-INFO-2021/11/05 11:12:17,032-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (1/8) (6eb90fb630b31d10a88c4107c4d4111b) [DEPLOYING].
-INFO-2021/11/05 11:12:17,033-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (2/8) (60de1add9d70fe4dbbd89c0fb3457988) [DEPLOYING].
-INFO-2021/11/05 11:12:17,034-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (3/8).
-INFO-2021/11/05 11:12:17,034-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (3/8) (74228519ed9557992d05bcb15e97486e) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:12:17,034-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot a80c2bed45d2918c32f67fb72f698ee5.
-INFO-2021/11/05 11:12:17,035-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (3/8) (74228519ed9557992d05bcb15e97486e) [DEPLOYING].
-INFO-2021/11/05 11:12:17,036-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (3/8) (74228519ed9557992d05bcb15e97486e) [DEPLOYING].
-INFO-2021/11/05 11:12:17,036-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (4/8).
-INFO-2021/11/05 11:12:17,037-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (4/8) (2528ad0fef5ac1fe2826623449be3178) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:12:17,037-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 1b6a8674322befce9b6783eee074b28d.
-INFO-2021/11/05 11:12:17,037-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (4/8) (2528ad0fef5ac1fe2826623449be3178) [DEPLOYING].
-INFO-2021/11/05 11:12:17,038-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (4/8) (2528ad0fef5ac1fe2826623449be3178) [DEPLOYING].
-INFO-2021/11/05 11:12:17,039-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (5/8).
-INFO-2021/11/05 11:12:17,039-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (5/8) (9ced5e992c312db477a02b37a38f63fb) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:12:17,039-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (5/8) (9ced5e992c312db477a02b37a38f63fb) [DEPLOYING].
-INFO-2021/11/05 11:12:17,039-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 8ebfe2a73c74dd3c8ab36def244e6711.
-INFO-2021/11/05 11:12:17,040-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (5/8) (9ced5e992c312db477a02b37a38f63fb) [DEPLOYING].
-INFO-2021/11/05 11:12:17,042-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (6/8).
-INFO-2021/11/05 11:12:17,043-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (6/8) (4adc68d7b4c7c0a2dbf9ebe99afdf712) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:12:17,043-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (6/8) (4adc68d7b4c7c0a2dbf9ebe99afdf712) [DEPLOYING].
-INFO-2021/11/05 11:12:17,043-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 5dc27f2f8d96b2fb173c0408f36121c6.
-INFO-2021/11/05 11:12:17,044-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (6/8) (4adc68d7b4c7c0a2dbf9ebe99afdf712) [DEPLOYING].
-INFO-2021/11/05 11:12:17,046-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (7/8).
-INFO-2021/11/05 11:12:17,047-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (7/8) (db50018cf1f799246f7cb37214807409) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:12:17,047-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (7/8) (db50018cf1f799246f7cb37214807409) [DEPLOYING].
-INFO-2021/11/05 11:12:17,047-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot a80c2bed45d2918c32f67fb72f698ee5.
-INFO-2021/11/05 11:12:17,048-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:12:17,048-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:12:17,048-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:12:17,048-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:12:17,048-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:12:17,048-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 8ebfe2a73c74dd3c8ab36def244e6711.
-INFO-2021/11/05 11:12:17,048-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:12:17,049-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 5dc27f2f8d96b2fb173c0408f36121c6.
-INFO-2021/11/05 11:12:17,048-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (7/8) (db50018cf1f799246f7cb37214807409) [DEPLOYING].
-INFO-2021/11/05 11:12:17,049-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot c8936f8296087c0165b5355a4fb6bfe5.
-INFO-2021/11/05 11:12:17,049-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 240639885a5ffe47701c787356492976.
-INFO-2021/11/05 11:12:17,050-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 60c76c6653665227ec2ffac20819cf52.
-INFO-2021/11/05 11:12:17,050-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 7c92e9cfb0f734659f932f7e1715abfc.
-INFO-2021/11/05 11:12:17,050-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 1b6a8674322befce9b6783eee074b28d.
-INFO-2021/11/05 11:12:17,050-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:12:17,050-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 60c76c6653665227ec2ffac20819cf52.
-INFO-2021/11/05 11:12:17,053-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (8/8).
-INFO-2021/11/05 11:12:17,053-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (8/8) (fa5289ab3851790fe0db34afa95a22fe) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:12:17,053-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (8/8) (fa5289ab3851790fe0db34afa95a22fe) [DEPLOYING].
-INFO-2021/11/05 11:12:17,054-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (8/8) (fa5289ab3851790fe0db34afa95a22fe) [DEPLOYING].
-INFO-2021/11/05 11:12:17,055-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:12:17,056-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (3/8) (74228519ed9557992d05bcb15e97486e) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,056-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (8/8) (fa5289ab3851790fe0db34afa95a22fe) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,056-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (7/8) (db50018cf1f799246f7cb37214807409) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,056-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (5/8) (9ced5e992c312db477a02b37a38f63fb) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,056-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (1/8) (6eb90fb630b31d10a88c4107c4d4111b) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,056-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (2/8) (60de1add9d70fe4dbbd89c0fb3457988) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,056-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (6/8) (4adc68d7b4c7c0a2dbf9ebe99afdf712) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,056-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (4/8) (2528ad0fef5ac1fe2826623449be3178) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,057-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (3/8) (74228519ed9557992d05bcb15e97486e) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,057-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (8/8) (fa5289ab3851790fe0db34afa95a22fe) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,058-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (7/8) (db50018cf1f799246f7cb37214807409) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,058-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (5/8) (9ced5e992c312db477a02b37a38f63fb) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,058-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (1/8) (6eb90fb630b31d10a88c4107c4d4111b) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,059-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (2/8) (60de1add9d70fe4dbbd89c0fb3457988) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,059-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (6/8) (4adc68d7b4c7c0a2dbf9ebe99afdf712) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,059-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (4/8) (2528ad0fef5ac1fe2826623449be3178) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:12:17,121-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 4 has no restore state.
-INFO-2021/11/05 11:12:17,121-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 0 has no restore state.
-INFO-2021/11/05 11:12:17,121-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 6 has no restore state.
-INFO-2021/11/05 11:12:17,121-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 2 has no restore state.
-INFO-2021/11/05 11:12:17,121-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 3 has no restore state.
-INFO-2021/11/05 11:12:17,121-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 7 has no restore state.
-INFO-2021/11/05 11:12:17,121-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 5 has no restore state.
-INFO-2021/11/05 11:12:17,121-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 1 has no restore state.
-INFO-2021/11/05 11:12:17,141-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:12:17,141-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:12:17,141-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:12:17,141-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:12:17,141-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:12:17,141-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:12:17,141-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:12:17,141-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-WARN-2021/11/05 11:12:17,218-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:12:17,218-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:12:17,218-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:12:17,218-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:12:17,218-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:12:17,218-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:12:17,219-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:12:17,219-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:12:17,220-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:12:17,220-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:12:17,221-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:12:17,222-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:12:17,222-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:12:17,222-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:12:17,222-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:12:17,222-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:12:17,222-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:12:17,223-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:12:17,223-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:12:17,223-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:12:17,223-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:12:17,223-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:12:17,223-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:12:17,224-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:12:17,390-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 3 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=4}]
-INFO-2021/11/05 11:12:17,390-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 0 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=1}]
-INFO-2021/11/05 11:12:17,390-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 6 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=7}]
-INFO-2021/11/05 11:12:17,390-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 7 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=0}]
-INFO-2021/11/05 11:12:17,391-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 2 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=3}]
-INFO-2021/11/05 11:12:17,391-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 5 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=6}]
-INFO-2021/11/05 11:12:17,391-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 4 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=5}]
-INFO-2021/11/05 11:12:17,391-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=2}]
-INFO-2021/11/05 11:12:17,396-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 4 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=5}=-915623761773}.
-INFO-2021/11/05 11:12:17,396-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 2 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=3}=-915623761773}.
-INFO-2021/11/05 11:12:17,396-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=2}=-915623761773}.
-INFO-2021/11/05 11:12:17,396-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=1}=-915623761773}.
-INFO-2021/11/05 11:12:17,396-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 7 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=0}=-915623761773}.
-INFO-2021/11/05 11:12:17,396-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 6 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=7}=-915623761773}.
-INFO-2021/11/05 11:12:17,396-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 5 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=6}=-915623761773}.
-INFO-2021/11/05 11:12:17,396-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 3 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=4}=-915623761773}.
-INFO-2021/11/05 11:12:17,409-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:12:17,410-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:12:17,410-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:12:17,409-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:12:17,409-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:12:17,409-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:12:17,410-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:12:17,410-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-WARN-2021/11/05 11:12:17,421-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:12:17,421-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:12:17,421-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-WARN-2021/11/05 11:12:17,422-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:12:17,422-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:12:17,422-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:12:17,422-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-WARN-2021/11/05 11:12:17,422-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:12:17,422-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:12:17,422-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-WARN-2021/11/05 11:12:17,422-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:12:17,423-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:12:17,423-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-WARN-2021/11/05 11:12:17,422-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:12:17,422-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:12:17,423-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-WARN-2021/11/05 11:12:17,423-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:12:17,423-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:12:17,424-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:12:17,424-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:12:17,424-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:12:17,424-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:12:17,424-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:12:17,424-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:12:17,498-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:12:17,498-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:12:17,498-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:12:17,498-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:12:17,498-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:12:17,498-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:12:17,498-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:12:17,498-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:12:17,648-org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch(Fetcher.java:875)-875-Fetch offset 37 is out of range for partition r_source01-2, resetting offset
-INFO-2021/11/05 11:12:17,648-org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch(Fetcher.java:875)-875-Fetch offset 36 is out of range for partition r_source01-4, resetting offset
-INFO-2021/11/05 11:12:17,648-org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch(Fetcher.java:875)-875-Fetch offset 36 is out of range for partition r_source01-7, resetting offset
-INFO-2021/11/05 11:12:17,648-org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch(Fetcher.java:875)-875-Fetch offset 36 is out of range for partition r_source01-1, resetting offset
-INFO-2021/11/05 11:12:17,648-org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch(Fetcher.java:875)-875-Fetch offset 38 is out of range for partition r_source01-3, resetting offset
-INFO-2021/11/05 11:12:17,648-org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch(Fetcher.java:875)-875-Fetch offset 38 is out of range for partition r_source01-5, resetting offset
-INFO-2021/11/05 11:12:17,648-org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch(Fetcher.java:875)-875-Fetch offset 37 is out of range for partition r_source01-6, resetting offset
-INFO-2021/11/05 11:12:17,648-org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch(Fetcher.java:875)-875-Fetch offset 35 is out of range for partition r_source01-0, resetting offset
-INFO-2021/11/05 11:15:28,029-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 11:15:28,150-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:15:28,150-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:15:43,792-org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager.shutdown(TaskExecutorLocalStateStoresManager.java:213)-213-Shutting down TaskExecutorLocalStateStoresManager.
-INFO-2021/11/05 11:15:43,792-org.apache.flink.runtime.blob.AbstractBlobCache.close(AbstractBlobCache.java:251)-251-Shutting down BLOB cache
-INFO-2021/11/05 11:15:43,792-org.apache.flink.runtime.blob.AbstractBlobCache.close(AbstractBlobCache.java:251)-251-Shutting down BLOB cache
-INFO-2021/11/05 11:15:43,808-org.apache.flink.runtime.io.disk.FileChannelManagerImpl.lambda$getFileCloser$0(FileChannelManagerImpl.java:146)-146-FileChannelManager removed spill file directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-io-ea608257-a8dd-4d4d-84d4-f8f80325ab02
-INFO-2021/11/05 11:15:43,814-org.apache.flink.runtime.blob.BlobServer.close(BlobServer.java:348)-348-Stopped BLOB server at 0.0.0.0:64079
-INFO-2021/11/05 11:15:43,816-org.apache.flink.runtime.io.disk.FileChannelManagerImpl.lambda$getFileCloser$0(FileChannelManagerImpl.java:146)-146-FileChannelManager removed spill file directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-netty-shuffle-9449fc1b-6d5f-46e1-9e92-1b44b01d9d01
-INFO-2021/11/05 11:15:43,816-org.apache.flink.runtime.filecache.FileCache.shutdown(FileCache.java:153)-153-removed file cache directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-dist-cache-2cacb5af-2163-42f3-b9cb-49eb8d0ee281
-INFO-2021/11/05 11:24:23,375-org.apache.flink.configuration.Configuration.loggingFallback(Configuration.java:857)-857-Config uses fallback configuration key 'rest.port' instead of key 'rest.bind-port'
-INFO-2021/11/05 11:24:23,383-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.cpu.cores' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 1.7976931348623157E308
-INFO-2021/11/05 11:24:23,386-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.memory.task.heap.size' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
-INFO-2021/11/05 11:24:23,386-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.memory.task.off-heap.size' , default: 0 bytes (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
-INFO-2021/11/05 11:24:23,387-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.memory.network.min' , default: 64 mb (fallback keys: [{key=taskmanager.network.memory.min, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
-INFO-2021/11/05 11:24:23,388-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.memory.network.max' , default: 1 gb (fallback keys: [{key=taskmanager.network.memory.max, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
-INFO-2021/11/05 11:24:23,391-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.memory.managed.size' , default: null (fallback keys: [{key=taskmanager.memory.size, isDeprecated=true}]) required for local execution is not set, setting it to its default value 128 mb
-INFO-2021/11/05 11:24:23,410-org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:251)-251-Starting Flink Mini Cluster
-INFO-2021/11/05 11:24:23,413-org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:260)-260-Starting Metrics Registry
-INFO-2021/11/05 11:24:23,464-org.apache.flink.runtime.metrics.MetricRegistryImpl.<init>(MetricRegistryImpl.java:115)-115-No metrics reporter configured, no metrics will be exposed/reported.
-INFO-2021/11/05 11:24:23,471-org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:264)-264-Starting RPC Service(s)
-INFO-2021/11/05 11:24:23,602-org.apache.flink.runtime.clusterframework.BootstrapTools.startLocalActorSystem(BootstrapTools.java:247)-247-Trying to start local actor system
-INFO-2021/11/05 11:24:24,082-akka.event.slf4j.Slf4jLogger$$anonfun$receive$1.applyOrElse(Slf4jLogger.scala:92)-92-Slf4jLogger started
-INFO-2021/11/05 11:24:24,520-org.apache.flink.runtime.clusterframework.BootstrapTools.startActorSystem(BootstrapTools.java:278)-278-Actor system started at akka://flink
-INFO-2021/11/05 11:24:24,534-org.apache.flink.runtime.clusterframework.BootstrapTools.startLocalActorSystem(BootstrapTools.java:247)-247-Trying to start local actor system
-INFO-2021/11/05 11:24:24,546-akka.event.slf4j.Slf4jLogger$$anonfun$receive$1.applyOrElse(Slf4jLogger.scala:92)-92-Slf4jLogger started
-INFO-2021/11/05 11:24:24,627-org.apache.flink.runtime.clusterframework.BootstrapTools.startActorSystem(BootstrapTools.java:278)-278-Actor system started at akka://flink-metrics
-INFO-2021/11/05 11:24:24,640-org.apache.flink.runtime.rpc.akka.AkkaRpcService.startServer(AkkaRpcService.java:225)-225-Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
-INFO-2021/11/05 11:24:24,718-org.apache.flink.runtime.minicluster.MiniCluster.createHighAvailabilityServices(MiniCluster.java:432)-432-Starting high-availability services
-INFO-2021/11/05 11:24:24,733-org.apache.flink.runtime.blob.BlobServer.<init>(BlobServer.java:143)-143-Created BLOB server storage directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/blobStore-2dc15d13-e27f-4d17-a93c-34cd4fb751e3
-INFO-2021/11/05 11:24:24,745-org.apache.flink.runtime.blob.BlobServer.<init>(BlobServer.java:207)-207-Started BLOB server at 0.0.0.0:50626 - max concurrent requests: 50 - max backlog: 1000
-INFO-2021/11/05 11:24:24,760-org.apache.flink.runtime.blob.AbstractBlobCache.<init>(AbstractBlobCache.java:107)-107-Created BLOB cache storage directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/blobStore-938a31f2-b5da-45c8-beec-6229665e1bae
-INFO-2021/11/05 11:24:24,761-org.apache.flink.runtime.blob.AbstractBlobCache.<init>(AbstractBlobCache.java:107)-107-Created BLOB cache storage directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/blobStore-76c431c6-7f4f-49f6-8c63-939158c348b2
-INFO-2021/11/05 11:24:24,762-org.apache.flink.runtime.minicluster.MiniCluster.startTaskManagers(MiniCluster.java:519)-519-Starting 1 TaskManger(s)
-INFO-2021/11/05 11:24:24,765-org.apache.flink.runtime.taskexecutor.TaskManagerRunner.startTaskManager(TaskManagerRunner.java:351)-351-Starting TaskManager with ResourceID: 73aa3074-91ac-4b1e-9951-ca1a62ed4872
-INFO-2021/11/05 11:24:24,810-org.apache.flink.runtime.taskexecutor.TaskManagerServices.checkTempDirs(TaskManagerServices.java:405)-405-Temporary file directory '/var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T': total 465 GB, usable 329 GB (70.75% usable)
-INFO-2021/11/05 11:24:24,814-org.apache.flink.runtime.io.disk.FileChannelManagerImpl.createFiles(FileChannelManagerImpl.java:97)-97-FileChannelManager uses directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-io-9865d697-38cd-49ee-b31e-7642c542152e for spill files.
-INFO-2021/11/05 11:24:24,823-org.apache.flink.runtime.io.disk.FileChannelManagerImpl.createFiles(FileChannelManagerImpl.java:97)-97-FileChannelManager uses directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-netty-shuffle-fc6c325f-77a3-4554-870c-a45c35802eac for spill files.
-INFO-2021/11/05 11:24:24,865-org.apache.flink.runtime.io.network.buffer.NetworkBufferPool.<init>(NetworkBufferPool.java:145)-145-Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
-INFO-2021/11/05 11:24:24,872-org.apache.flink.runtime.io.network.NettyShuffleEnvironment.start(NettyShuffleEnvironment.java:293)-293-Starting the network environment and its components.
-INFO-2021/11/05 11:24:24,875-org.apache.flink.runtime.taskexecutor.KvStateService.start(KvStateService.java:89)-89-Starting the kvState service and its components.
-INFO-2021/11/05 11:24:24,897-org.apache.flink.runtime.rpc.akka.AkkaRpcService.startServer(AkkaRpcService.java:225)-225-Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
-INFO-2021/11/05 11:24:24,912-org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService.start(DefaultJobLeaderService.java:116)-116-Start job leader service.
-INFO-2021/11/05 11:24:24,914-org.apache.flink.runtime.filecache.FileCache.<init>(FileCache.java:107)-107-User file cache uses directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-dist-cache-10a2dc66-dbfd-44dd-ad78-c95cf0774fb4
-INFO-2021/11/05 11:24:24,937-org.apache.flink.configuration.Configuration.loggingFallback(Configuration.java:857)-857-Config uses fallback configuration key 'rest.port' instead of key 'rest.bind-port'
-INFO-2021/11/05 11:24:24,977-org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:140)-140-Starting rest endpoint.
-WARN-2021/11/05 11:24:25,277-org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation.find(WebMonitorUtils.java:91)-91-Log file environment variable 'log.file' is not set.
-WARN-2021/11/05 11:24:25,277-org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation.find(WebMonitorUtils.java:97)-97-JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
-INFO-2021/11/05 11:24:25,513-org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:236)-236-Rest endpoint listening at localhost:8081
-INFO-2021/11/05 11:24:25,514-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.updateLeader(EmbeddedLeaderService.java:302)-302-Proposing leadership to contender http://localhost:8081
-INFO-2021/11/05 11:24:25,517-org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.startInternal(WebMonitorEndpoint.java:756)-756-Web frontend listening at http://localhost:8081.
-INFO-2021/11/05 11:24:25,517-org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.grantLeadership(WebMonitorEndpoint.java:812)-812-http://localhost:8081 was granted leadership with leaderSessionID=eebb5aa3-153d-40c9-aa6b-b22e4971865e
-INFO-2021/11/05 11:24:25,517-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.confirmLeader(EmbeddedLeaderService.java:252)-252-Received confirmation of leadership for leader http://localhost:8081 , session=eebb5aa3-153d-40c9-aa6b-b22e4971865e
-INFO-2021/11/05 11:24:25,532-org.apache.flink.runtime.rpc.akka.AkkaRpcService.startServer(AkkaRpcService.java:225)-225-Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
-INFO-2021/11/05 11:24:25,550-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.updateLeader(EmbeddedLeaderService.java:302)-302-Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
-INFO-2021/11/05 11:24:25,551-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.updateLeader(EmbeddedLeaderService.java:302)-302-Proposing leadership to contender LeaderContender: StandaloneResourceManager
-INFO-2021/11/05 11:24:25,554-org.apache.flink.runtime.resourcemanager.ResourceManager.tryAcceptLeadership(ResourceManager.java:984)-984-ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token b2b3afc50582b8a7af3c7c48dad24fff
-INFO-2021/11/05 11:24:25,556-org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:372)-372-Flink Mini Cluster started successfully
-INFO-2021/11/05 11:24:25,560-org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl.start(SlotManagerImpl.java:279)-279-Starting the SlotManager.
-INFO-2021/11/05 11:24:25,561-org.apache.flink.runtime.dispatcher.runner.AbstractDispatcherLeaderProcess.startInternal(AbstractDispatcherLeaderProcess.java:101)-101-Start SessionDispatcherLeaderProcess.
-INFO-2021/11/05 11:24:25,565-org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess.recoverJobs(SessionDispatcherLeaderProcess.java:120)-120-Recover all persisted job graphs.
-INFO-2021/11/05 11:24:25,566-org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess.recoverJobs(SessionDispatcherLeaderProcess.java:128)-128-Successfully recovered 0 persisted job graphs.
-INFO-2021/11/05 11:24:25,567-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.confirmLeader(EmbeddedLeaderService.java:252)-252-Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=af3c7c48-dad2-4fff-b2b3-afc50582b8a7
-INFO-2021/11/05 11:24:25,571-org.apache.flink.runtime.taskexecutor.TaskExecutor.connectToResourceManager(TaskExecutor.java:1123)-1123-Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b2b3afc50582b8a7af3c7c48dad24fff).
-INFO-2021/11/05 11:24:25,575-org.apache.flink.runtime.rpc.akka.AkkaRpcService.startServer(AkkaRpcService.java:225)-225-Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
-INFO-2021/11/05 11:24:25,589-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.confirmLeader(EmbeddedLeaderService.java:252)-252-Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=6d613d91-da53-45f8-8395-680dbe5c6469
-INFO-2021/11/05 11:24:25,601-org.apache.flink.runtime.registration.RetryingRegistration.lambda$startRegistration$0(RetryingRegistration.java:155)-155-Resolved ResourceManager address, beginning registration
-INFO-2021/11/05 11:24:25,610-org.apache.flink.runtime.resourcemanager.ResourceManager.registerTaskExecutorInternal(ResourceManager.java:781)-781-Registering TaskManager with ResourceID 73aa3074-91ac-4b1e-9951-ca1a62ed4872 (akka://flink/user/rpc/taskmanager_0) at ResourceManager
-INFO-2021/11/05 11:24:25,614-org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection.onRegistrationSuccess(TaskExecutorToResourceManagerConnection.java:84)-84-Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 5dafc94fde227f8eccf11c839304be9e.
-INFO-2021/11/05 11:24:25,616-org.apache.flink.runtime.dispatcher.Dispatcher.submitJob(Dispatcher.java:275)-275-Received JobGraph submission eff4ca8d3c29e541ce43aa1f922f9f25 (this is kafka_test).
-INFO-2021/11/05 11:24:25,616-org.apache.flink.runtime.dispatcher.Dispatcher.internalSubmitJob(Dispatcher.java:332)-332-Submitting job eff4ca8d3c29e541ce43aa1f922f9f25 (this is kafka_test).
-INFO-2021/11/05 11:24:25,648-org.apache.flink.runtime.rpc.akka.AkkaRpcService.startServer(AkkaRpcService.java:225)-225-Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
-INFO-2021/11/05 11:24:25,656-org.apache.flink.runtime.jobmaster.JobMaster.<init>(JobMaster.java:248)-248-Initializing job this is kafka_test (eff4ca8d3c29e541ce43aa1f922f9f25).
-INFO-2021/11/05 11:24:25,671-org.apache.flink.runtime.scheduler.DefaultSchedulerFactory.createInstance(DefaultSchedulerFactory.java:80)-80-Using restart back off time strategy NoRestartBackoffTimeStrategy for this is kafka_test (eff4ca8d3c29e541ce43aa1f922f9f25).
-INFO-2021/11/05 11:24:25,797-org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder.buildGraph(ExecutionGraphBuilder.java:202)-202-Running initialization on master for job this is kafka_test (eff4ca8d3c29e541ce43aa1f922f9f25).
-INFO-2021/11/05 11:24:25,798-org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder.buildGraph(ExecutionGraphBuilder.java:220)-220-Successfully ran initialization on master in 0 ms.
-INFO-2021/11/05 11:24:25,820-org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology.initializePipelinedRegions(DefaultExecutionTopology.java:111)-111-Built 8 pipelined regions in 0 ms
-INFO-2021/11/05 11:24:25,839-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:24:25,858-org.apache.flink.runtime.scheduler.DefaultScheduler.<init>(DefaultScheduler.java:148)-148-Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@68627f0b for this is kafka_test (eff4ca8d3c29e541ce43aa1f922f9f25).
-INFO-2021/11/05 11:24:25,861-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.updateLeader(EmbeddedLeaderService.java:302)-302-Proposing leadership to contender akka://flink/user/rpc/jobmanager_3
-INFO-2021/11/05 11:24:25,862-org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl.startJobMaster(JobManagerRunnerImpl.java:304)-304-JobManager runner for job this is kafka_test (eff4ca8d3c29e541ce43aa1f922f9f25) was granted leadership with session id 9f7967e7-d081-4508-b53a-7d62f7bc1512 at akka://flink/user/rpc/jobmanager_3.
-INFO-2021/11/05 11:24:25,866-org.apache.flink.runtime.jobmaster.JobMaster.startJobExecution(JobMaster.java:758)-758-Starting execution of job this is kafka_test (eff4ca8d3c29e541ce43aa1f922f9f25) under job master id b53a7d62f7bc15129f7967e7d0814508.
-INFO-2021/11/05 11:24:25,870-org.apache.flink.runtime.scheduler.DefaultScheduler.startSchedulingInternal(DefaultScheduler.java:171)-171-Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.EagerSchedulingStrategy]
-INFO-2021/11/05 11:24:25,871-org.apache.flink.runtime.executiongraph.ExecutionGraph.transitionState(ExecutionGraph.java:1240)-1240-Job this is kafka_test (eff4ca8d3c29e541ce43aa1f922f9f25) switched from state CREATED to RUNNING.
-INFO-2021/11/05 11:24:25,881-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (1/8) (780f61caf1eae5ad9e5cdf084a96ad96) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:24:25,882-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (2/8) (aa319bea80f5e6c2a31a1de1ba88c647) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:24:25,883-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (3/8) (98fe1b8cc558e186c1efeddeee4cb598) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:24:25,883-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (4/8) (d13937890a507b85ad81d3fdcd5b54eb) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:24:25,883-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (5/8) (cb69f4924aa928fe2a0f497e1fd4500e) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:24:25,883-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (6/8) (6150fdce982bfbea2875788eabb535e2) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:24:25,883-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (7/8) (467e12a8cb5adf3c5143904cacde6f41) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:24:25,883-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (8/8) (ea6dfde5d49ec269a62be3e91036401d) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:24:25,901-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{3af6268cdd1d537fa5636a124641ae2b}]
-INFO-2021/11/05 11:24:25,906-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b135b364c9678f97f77c25bdaf98882b}]
-INFO-2021/11/05 11:24:25,907-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{90bf71703d254fef21a049b0e83ffa23}]
-INFO-2021/11/05 11:24:25,907-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{7d2bd7776fbac0e3f0b6df1856724cfe}]
-INFO-2021/11/05 11:24:25,907-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{79125886ff1aafcc690f1c03becbaba0}]
-INFO-2021/11/05 11:24:25,908-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{37f6f4ef727fae4936fab2cbca1a950b}]
-INFO-2021/11/05 11:24:25,908-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{a9afba79052993cf18f1c2a498a976d2}]
-INFO-2021/11/05 11:24:25,909-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{4e230fed648509742612a580286cfbc3}]
-INFO-2021/11/05 11:24:25,912-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.confirmLeader(EmbeddedLeaderService.java:252)-252-Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=9f7967e7-d081-4508-b53a-7d62f7bc1512
-INFO-2021/11/05 11:24:25,912-org.apache.flink.runtime.jobmaster.JobMaster.connectToResourceManager(JobMaster.java:984)-984-Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b2b3afc50582b8a7af3c7c48dad24fff)
-INFO-2021/11/05 11:24:25,915-org.apache.flink.runtime.registration.RetryingRegistration.lambda$startRegistration$0(RetryingRegistration.java:155)-155-Resolved ResourceManager address, beginning registration
-INFO-2021/11/05 11:24:25,927-org.apache.flink.runtime.resourcemanager.ResourceManager.registerJobManager(ResourceManager.java:317)-317-Registering job manager b53a7d62f7bc15129f7967e7d0814508@akka://flink/user/rpc/jobmanager_3 for job eff4ca8d3c29e541ce43aa1f922f9f25.
-INFO-2021/11/05 11:24:25,942-org.apache.flink.runtime.resourcemanager.ResourceManager.registerJobMasterInternal(ResourceManager.java:727)-727-Registered job manager b53a7d62f7bc15129f7967e7d0814508@akka://flink/user/rpc/jobmanager_3 for job eff4ca8d3c29e541ce43aa1f922f9f25.
-INFO-2021/11/05 11:24:25,944-org.apache.flink.runtime.jobmaster.JobMaster.establishResourceManagerConnection(JobMaster.java:1006)-1006-JobManager successfully registered at ResourceManager, leader id: b2b3afc50582b8a7af3c7c48dad24fff.
-INFO-2021/11/05 11:24:25,945-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{3af6268cdd1d537fa5636a124641ae2b}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:24:25,950-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{b135b364c9678f97f77c25bdaf98882b}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:24:25,950-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job eff4ca8d3c29e541ce43aa1f922f9f25 with allocation id 647ba08b602c907cebcb8f9fe87284f3.
-INFO-2021/11/05 11:24:25,951-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{90bf71703d254fef21a049b0e83ffa23}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:24:25,952-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{7d2bd7776fbac0e3f0b6df1856724cfe}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:24:25,953-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{79125886ff1aafcc690f1c03becbaba0}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:24:25,953-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{37f6f4ef727fae4936fab2cbca1a950b}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:24:25,954-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{a9afba79052993cf18f1c2a498a976d2}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:24:25,954-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{4e230fed648509742612a580286cfbc3}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:24:25,958-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job eff4ca8d3c29e541ce43aa1f922f9f25 with allocation id 7d28e7c36bf30bf94bfb1723596cdad1.
-INFO-2021/11/05 11:24:25,959-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job eff4ca8d3c29e541ce43aa1f922f9f25 with allocation id ee6ad58aaf6ddb51789f8fbbbc4fc08f.
-INFO-2021/11/05 11:24:25,960-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 647ba08b602c907cebcb8f9fe87284f3 for job eff4ca8d3c29e541ce43aa1f922f9f25 from resource manager with leader id b2b3afc50582b8a7af3c7c48dad24fff.
-INFO-2021/11/05 11:24:25,960-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job eff4ca8d3c29e541ce43aa1f922f9f25 with allocation id e9ae3322903bca5848eb7b119b549317.
-INFO-2021/11/05 11:24:25,964-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job eff4ca8d3c29e541ce43aa1f922f9f25 with allocation id 5afe362742429016833f718ad193323f.
-INFO-2021/11/05 11:24:25,965-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job eff4ca8d3c29e541ce43aa1f922f9f25 with allocation id 15e8e1257420e5ca7a1b87012c339973.
-INFO-2021/11/05 11:24:25,966-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job eff4ca8d3c29e541ce43aa1f922f9f25 with allocation id f5f0596fe9fc8a320775c6b3fe8dde91.
-INFO-2021/11/05 11:24:25,967-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job eff4ca8d3c29e541ce43aa1f922f9f25 with allocation id 615b46336416b5090f67fa80a310bb14.
-INFO-2021/11/05 11:24:25,968-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 647ba08b602c907cebcb8f9fe87284f3.
-INFO-2021/11/05 11:24:25,971-org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService.addJob(DefaultJobLeaderService.java:172)-172-Add job eff4ca8d3c29e541ce43aa1f922f9f25 for job leader monitoring.
-INFO-2021/11/05 11:24:25,975-org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener.openRpcConnectionTo(DefaultJobLeaderService.java:314)-314-Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id 9f7967e7-d081-4508-b53a-7d62f7bc1512.
-INFO-2021/11/05 11:24:25,978-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 7d28e7c36bf30bf94bfb1723596cdad1 for job eff4ca8d3c29e541ce43aa1f922f9f25 from resource manager with leader id b2b3afc50582b8a7af3c7c48dad24fff.
-INFO-2021/11/05 11:24:25,979-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 7d28e7c36bf30bf94bfb1723596cdad1.
-INFO-2021/11/05 11:24:25,980-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request ee6ad58aaf6ddb51789f8fbbbc4fc08f for job eff4ca8d3c29e541ce43aa1f922f9f25 from resource manager with leader id b2b3afc50582b8a7af3c7c48dad24fff.
-INFO-2021/11/05 11:24:25,980-org.apache.flink.runtime.registration.RetryingRegistration.lambda$startRegistration$0(RetryingRegistration.java:155)-155-Resolved JobManager address, beginning registration
-INFO-2021/11/05 11:24:25,981-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for ee6ad58aaf6ddb51789f8fbbbc4fc08f.
-INFO-2021/11/05 11:24:25,982-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request e9ae3322903bca5848eb7b119b549317 for job eff4ca8d3c29e541ce43aa1f922f9f25 from resource manager with leader id b2b3afc50582b8a7af3c7c48dad24fff.
-INFO-2021/11/05 11:24:25,983-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for e9ae3322903bca5848eb7b119b549317.
-INFO-2021/11/05 11:24:25,983-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 5afe362742429016833f718ad193323f for job eff4ca8d3c29e541ce43aa1f922f9f25 from resource manager with leader id b2b3afc50582b8a7af3c7c48dad24fff.
-INFO-2021/11/05 11:24:25,984-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 5afe362742429016833f718ad193323f.
-INFO-2021/11/05 11:24:25,985-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 15e8e1257420e5ca7a1b87012c339973 for job eff4ca8d3c29e541ce43aa1f922f9f25 from resource manager with leader id b2b3afc50582b8a7af3c7c48dad24fff.
-INFO-2021/11/05 11:24:25,986-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 15e8e1257420e5ca7a1b87012c339973.
-INFO-2021/11/05 11:24:25,986-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request f5f0596fe9fc8a320775c6b3fe8dde91 for job eff4ca8d3c29e541ce43aa1f922f9f25 from resource manager with leader id b2b3afc50582b8a7af3c7c48dad24fff.
-INFO-2021/11/05 11:24:25,986-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for f5f0596fe9fc8a320775c6b3fe8dde91.
-INFO-2021/11/05 11:24:25,987-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 615b46336416b5090f67fa80a310bb14 for job eff4ca8d3c29e541ce43aa1f922f9f25 from resource manager with leader id b2b3afc50582b8a7af3c7c48dad24fff.
-INFO-2021/11/05 11:24:25,987-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 615b46336416b5090f67fa80a310bb14.
-INFO-2021/11/05 11:24:25,990-org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection.onRegistrationSuccess(DefaultJobLeaderService.java:369)-369-Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job eff4ca8d3c29e541ce43aa1f922f9f25.
-INFO-2021/11/05 11:24:25,992-org.apache.flink.runtime.taskexecutor.TaskExecutor.establishJobManagerConnection(TaskExecutor.java:1372)-1372-Establish JobManager connection for job eff4ca8d3c29e541ce43aa1f922f9f25.
-INFO-2021/11/05 11:24:25,997-org.apache.flink.runtime.taskexecutor.TaskExecutor.internalOfferSlotsToJobManager(TaskExecutor.java:1271)-1271-Offer reserved slots to the leader of job eff4ca8d3c29e541ce43aa1f922f9f25.
-INFO-2021/11/05 11:24:26,009-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (1/8) (780f61caf1eae5ad9e5cdf084a96ad96) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:24:26,009-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (1/8) (attempt #0) to 73aa3074-91ac-4b1e-9951-ca1a62ed4872 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:24:26,044-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (2/8) (aa319bea80f5e6c2a31a1de1ba88c647) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:24:26,044-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 647ba08b602c907cebcb8f9fe87284f3.
-INFO-2021/11/05 11:24:26,045-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (2/8) (attempt #0) to 73aa3074-91ac-4b1e-9951-ca1a62ed4872 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:24:26,046-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (3/8) (98fe1b8cc558e186c1efeddeee4cb598) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:24:26,046-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (3/8) (attempt #0) to 73aa3074-91ac-4b1e-9951-ca1a62ed4872 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:24:26,047-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (4/8) (d13937890a507b85ad81d3fdcd5b54eb) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:24:26,048-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (4/8) (attempt #0) to 73aa3074-91ac-4b1e-9951-ca1a62ed4872 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:24:26,048-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (5/8) (cb69f4924aa928fe2a0f497e1fd4500e) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:24:26,049-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (5/8) (attempt #0) to 73aa3074-91ac-4b1e-9951-ca1a62ed4872 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:24:26,049-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (6/8) (6150fdce982bfbea2875788eabb535e2) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:24:26,050-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (6/8) (attempt #0) to 73aa3074-91ac-4b1e-9951-ca1a62ed4872 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:24:26,050-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (7/8) (467e12a8cb5adf3c5143904cacde6f41) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:24:26,051-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (7/8) (attempt #0) to 73aa3074-91ac-4b1e-9951-ca1a62ed4872 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:24:26,051-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (8/8) (ea6dfde5d49ec269a62be3e91036401d) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:24:26,051-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (8/8) (attempt #0) to 73aa3074-91ac-4b1e-9951-ca1a62ed4872 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:24:26,087-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (1/8).
-INFO-2021/11/05 11:24:26,088-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (1/8) (780f61caf1eae5ad9e5cdf084a96ad96) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:24:26,093-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 7d28e7c36bf30bf94bfb1723596cdad1.
-INFO-2021/11/05 11:24:26,095-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (1/8) (780f61caf1eae5ad9e5cdf084a96ad96) [DEPLOYING].
-INFO-2021/11/05 11:24:26,097-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (1/8) (780f61caf1eae5ad9e5cdf084a96ad96) [DEPLOYING].
-INFO-2021/11/05 11:24:26,101-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (2/8).
-INFO-2021/11/05 11:24:26,102-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (2/8) (aa319bea80f5e6c2a31a1de1ba88c647) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:24:26,102-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (2/8) (aa319bea80f5e6c2a31a1de1ba88c647) [DEPLOYING].
-INFO-2021/11/05 11:24:26,103-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot ee6ad58aaf6ddb51789f8fbbbc4fc08f.
-INFO-2021/11/05 11:24:26,104-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (2/8) (aa319bea80f5e6c2a31a1de1ba88c647) [DEPLOYING].
-INFO-2021/11/05 11:24:26,106-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (3/8).
-INFO-2021/11/05 11:24:26,107-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (3/8) (98fe1b8cc558e186c1efeddeee4cb598) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:24:26,108-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (3/8) (98fe1b8cc558e186c1efeddeee4cb598) [DEPLOYING].
-INFO-2021/11/05 11:24:26,108-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot e9ae3322903bca5848eb7b119b549317.
-INFO-2021/11/05 11:24:26,109-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (3/8) (98fe1b8cc558e186c1efeddeee4cb598) [DEPLOYING].
-INFO-2021/11/05 11:24:26,112-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (4/8).
-INFO-2021/11/05 11:24:26,113-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (4/8) (d13937890a507b85ad81d3fdcd5b54eb) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:24:26,114-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (4/8) (d13937890a507b85ad81d3fdcd5b54eb) [DEPLOYING].
-INFO-2021/11/05 11:24:26,114-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 5afe362742429016833f718ad193323f.
-INFO-2021/11/05 11:24:26,116-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (4/8) (d13937890a507b85ad81d3fdcd5b54eb) [DEPLOYING].
-INFO-2021/11/05 11:24:26,120-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:24:26,120-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:24:26,120-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:24:26,120-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:24:26,122-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (5/8).
-INFO-2021/11/05 11:24:26,123-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (5/8) (cb69f4924aa928fe2a0f497e1fd4500e) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:24:26,124-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (5/8) (cb69f4924aa928fe2a0f497e1fd4500e) [DEPLOYING].
-INFO-2021/11/05 11:24:26,125-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (5/8) (cb69f4924aa928fe2a0f497e1fd4500e) [DEPLOYING].
-INFO-2021/11/05 11:24:26,125-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 15e8e1257420e5ca7a1b87012c339973.
-INFO-2021/11/05 11:24:26,126-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:24:26,129-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (6/8).
-INFO-2021/11/05 11:24:26,130-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (3/8) (98fe1b8cc558e186c1efeddeee4cb598) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,130-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (5/8) (cb69f4924aa928fe2a0f497e1fd4500e) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,130-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (1/8) (780f61caf1eae5ad9e5cdf084a96ad96) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,130-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (2/8) (aa319bea80f5e6c2a31a1de1ba88c647) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,130-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (4/8) (d13937890a507b85ad81d3fdcd5b54eb) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,132-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (3/8) (98fe1b8cc558e186c1efeddeee4cb598) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,133-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (5/8) (cb69f4924aa928fe2a0f497e1fd4500e) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,134-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (1/8) (780f61caf1eae5ad9e5cdf084a96ad96) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,135-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (2/8) (aa319bea80f5e6c2a31a1de1ba88c647) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,136-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (4/8) (d13937890a507b85ad81d3fdcd5b54eb) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,132-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot f5f0596fe9fc8a320775c6b3fe8dde91.
-INFO-2021/11/05 11:24:26,131-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (6/8) (6150fdce982bfbea2875788eabb535e2) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:24:26,137-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (6/8) (6150fdce982bfbea2875788eabb535e2) [DEPLOYING].
-INFO-2021/11/05 11:24:26,139-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (6/8) (6150fdce982bfbea2875788eabb535e2) [DEPLOYING].
-INFO-2021/11/05 11:24:26,140-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:24:26,141-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (6/8) (6150fdce982bfbea2875788eabb535e2) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,141-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (6/8) (6150fdce982bfbea2875788eabb535e2) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,144-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (7/8).
-INFO-2021/11/05 11:24:26,147-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (7/8) (467e12a8cb5adf3c5143904cacde6f41) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:24:26,148-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (7/8) (467e12a8cb5adf3c5143904cacde6f41) [DEPLOYING].
-INFO-2021/11/05 11:24:26,149-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 615b46336416b5090f67fa80a310bb14.
-INFO-2021/11/05 11:24:26,149-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (7/8) (467e12a8cb5adf3c5143904cacde6f41) [DEPLOYING].
-INFO-2021/11/05 11:24:26,151-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:24:26,152-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (7/8) (467e12a8cb5adf3c5143904cacde6f41) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,152-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (7/8) (467e12a8cb5adf3c5143904cacde6f41) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,155-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (8/8).
-INFO-2021/11/05 11:24:26,157-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (8/8) (ea6dfde5d49ec269a62be3e91036401d) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:24:26,157-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (8/8) (ea6dfde5d49ec269a62be3e91036401d) [DEPLOYING].
-INFO-2021/11/05 11:24:26,158-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (8/8) (ea6dfde5d49ec269a62be3e91036401d) [DEPLOYING].
-INFO-2021/11/05 11:24:26,159-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:24:26,160-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (8/8) (ea6dfde5d49ec269a62be3e91036401d) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,160-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (8/8) (ea6dfde5d49ec269a62be3e91036401d) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:24:26,161-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 7d28e7c36bf30bf94bfb1723596cdad1.
-INFO-2021/11/05 11:24:26,161-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 5afe362742429016833f718ad193323f.
-INFO-2021/11/05 11:24:26,163-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 615b46336416b5090f67fa80a310bb14.
-INFO-2021/11/05 11:24:26,163-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 647ba08b602c907cebcb8f9fe87284f3.
-INFO-2021/11/05 11:24:26,164-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot e9ae3322903bca5848eb7b119b549317.
-INFO-2021/11/05 11:24:26,165-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot ee6ad58aaf6ddb51789f8fbbbc4fc08f.
-INFO-2021/11/05 11:24:26,165-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot f5f0596fe9fc8a320775c6b3fe8dde91.
-INFO-2021/11/05 11:24:26,165-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 15e8e1257420e5ca7a1b87012c339973.
-INFO-2021/11/05 11:24:26,208-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 4 has no restore state.
-INFO-2021/11/05 11:24:26,208-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 5 has no restore state.
-INFO-2021/11/05 11:24:26,208-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 7 has no restore state.
-INFO-2021/11/05 11:24:26,208-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 1 has no restore state.
-INFO-2021/11/05 11:24:26,208-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 2 has no restore state.
-INFO-2021/11/05 11:24:26,208-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 3 has no restore state.
-INFO-2021/11/05 11:24:26,208-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 6 has no restore state.
-INFO-2021/11/05 11:24:26,208-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 0 has no restore state.
-INFO-2021/11/05 11:24:26,233-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:24:26,233-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:24:26,233-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:24:26,233-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:24:26,233-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:24:26,233-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:24:26,233-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:24:26,233-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-WARN-2021/11/05 11:24:26,327-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:24:26,328-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:24:26,328-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:24:26,329-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:24:26,329-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:24:26,330-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:24:26,331-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:24:26,331-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-WARN-2021/11/05 11:24:26,332-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:24:26,332-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:24:26,334-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:26,334-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:24:26,335-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:26,335-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:24:26,335-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:26,336-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:24:26,336-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:26,336-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:24:26,337-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:26,337-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:24:26,337-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:26,337-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:24:26,338-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:26,338-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:24:26,588-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 7 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=0}]
-INFO-2021/11/05 11:24:26,588-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 0 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=1}]
-INFO-2021/11/05 11:24:26,588-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 6 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=7}]
-INFO-2021/11/05 11:24:26,588-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 4 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=5}]
-INFO-2021/11/05 11:24:26,593-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 6 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=7}=-915623761773}.
-INFO-2021/11/05 11:24:26,593-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 4 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=5}=-915623761773}.
-INFO-2021/11/05 11:24:26,593-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 7 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=0}=-915623761773}.
-INFO-2021/11/05 11:24:26,593-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=1}=-915623761773}.
-INFO-2021/11/05 11:24:26,594-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 3 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=4}]
-INFO-2021/11/05 11:24:26,594-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 3 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=4}=-915623761773}.
-INFO-2021/11/05 11:24:26,594-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=2}]
-INFO-2021/11/05 11:24:26,595-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=2}=-915623761773}.
-INFO-2021/11/05 11:24:26,599-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 5 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=6}]
-INFO-2021/11/05 11:24:26,600-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 5 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=6}=-915623761773}.
-INFO-2021/11/05 11:24:26,602-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:24:26,603-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:24:26,603-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:24:26,602-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:24:26,602-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:24:26,602-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:24:26,603-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:24:26,605-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 2 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=3}]
-INFO-2021/11/05 11:24:26,606-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 2 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=3}=-915623761773}.
-INFO-2021/11/05 11:24:26,607-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-WARN-2021/11/05 11:24:26,610-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:24:26,610-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:26,610-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-WARN-2021/11/05 11:24:26,610-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:24:26,611-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:26,611-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-WARN-2021/11/05 11:24:26,612-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:24:26,612-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:26,612-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-WARN-2021/11/05 11:24:26,612-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:24:26,613-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:24:26,613-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:26,613-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-WARN-2021/11/05 11:24:26,613-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:24:26,613-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:26,613-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-WARN-2021/11/05 11:24:26,613-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:24:26,613-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:26,614-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:24:26,614-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:26,614-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-WARN-2021/11/05 11:24:26,614-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:24:26,615-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:26,615-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:24:26,869-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:24:26,869-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:24:26,937-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:24:26,938-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:24:27,124-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:24:27,124-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:24:27,321-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:24:27,456-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:24:29,854-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 11:24:29,980-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:24:29,980-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-ERROR-2021/11/05 11:24:50,815-org.apache.flink.runtime.rest.handler.taskmanager.AbstractTaskManagerFileHandler.lambda$respondToRequest$1(AbstractTaskManagerFileHandler.java:136)-136-Failed to transfer file from TaskExecutor 73aa3074-91ac-4b1e-9951-ca1a62ed4872.
java.util.concurrent.CompletionException: org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniAccept(CompletableFuture.java:661)
	at java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:646)
	at java.util.concurrent.CompletableFuture.uniAcceptStage(CompletableFuture.java:686)
	at java.util.concurrent.CompletableFuture.thenAcceptAsync(CompletableFuture.java:2019)
	at org.apache.flink.runtime.rest.handler.taskmanager.AbstractTaskManagerFileHandler.respondToRequest(AbstractTaskManagerFileHandler.java:113)
	at org.apache.flink.runtime.rest.handler.AbstractHandler.respondAsLeader(AbstractHandler.java:172)
	at org.apache.flink.runtime.rest.handler.LeaderRetrievalHandler.lambda$channelRead0$0(LeaderRetrievalHandler.java:81)
	at java.util.Optional.ifPresent(Optional.java:159)
	at org.apache.flink.util.OptionalConsumer.ifPresent(OptionalConsumer.java:46)
	at org.apache.flink.runtime.rest.handler.LeaderRetrievalHandler.channelRead0(LeaderRetrievalHandler.java:78)
	at org.apache.flink.runtime.rest.handler.LeaderRetrievalHandler.channelRead0(LeaderRetrievalHandler.java:49)
	at org.apache.flink.shaded.netty4.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at org.apache.flink.runtime.rest.handler.router.RouterHandler.routed(RouterHandler.java:110)
	at org.apache.flink.runtime.rest.handler.router.RouterHandler.channelRead0(RouterHandler.java:89)
	at org.apache.flink.runtime.rest.handler.router.RouterHandler.channelRead0(RouterHandler.java:54)
	at org.apache.flink.shaded.netty4.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at org.apache.flink.runtime.rest.FileUploadHandler.channelRead0(FileUploadHandler.java:174)
	at org.apache.flink.runtime.rest.FileUploadHandler.channelRead0(FileUploadHandler.java:68)
	at org.apache.flink.shaded.netty4.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at org.apache.flink.shaded.netty4.io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:438)
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:328)
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:302)
	at org.apache.flink.shaded.netty4.io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:253)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at org.apache.flink.shaded.netty4.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1421)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at org.apache.flink.shaded.netty4.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697)
	at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632)
	at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549)
	at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511)
	at org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918)
	at org.apache.flink.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
-ERROR-2021/11/05 11:24:50,819-org.apache.flink.runtime.rest.handler.AbstractHandler.handleException(AbstractHandler.java:219)-219-Unhandled exception.
org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
-ERROR-2021/11/05 11:24:59,257-org.apache.flink.runtime.rest.handler.taskmanager.AbstractTaskManagerFileHandler.lambda$respondToRequest$1(AbstractTaskManagerFileHandler.java:136)-136-Failed to transfer file from TaskExecutor 73aa3074-91ac-4b1e-9951-ca1a62ed4872.
java.util.concurrent.CompletionException: org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniAccept(CompletableFuture.java:661)
	at java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:646)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)
	at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.lambda$invokeRpc$0(AkkaInvocationHandler.java:227)
	at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)
	at org.apache.flink.runtime.concurrent.FutureUtils$1.onComplete(FutureUtils.java:890)
	at akka.dispatch.OnComplete.internal(Future.scala:263)
	at akka.dispatch.OnComplete.internal(Future.scala:261)
	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:191)
	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:188)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)
	at org.apache.flink.runtime.concurrent.Executors$DirectExecutionContext.execute(Executors.java:74)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:44)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:252)
	at akka.pattern.PromiseActorRef.$bang(AskSupport.scala:572)
	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:23)
	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:21)
	at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:436)
	at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:435)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)
	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	... 4 more
-ERROR-2021/11/05 11:24:59,259-org.apache.flink.runtime.rest.handler.AbstractHandler.handleException(AbstractHandler.java:219)-219-Unhandled exception.
org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
-ERROR-2021/11/05 11:24:59,943-org.apache.flink.runtime.rest.handler.taskmanager.AbstractTaskManagerFileHandler.lambda$respondToRequest$1(AbstractTaskManagerFileHandler.java:136)-136-Failed to transfer file from TaskExecutor 73aa3074-91ac-4b1e-9951-ca1a62ed4872.
java.util.concurrent.CompletionException: org.apache.flink.util.FlinkException: The file STDOUT is not available on the TaskExecutor.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniAccept(CompletableFuture.java:661)
	at java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:646)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)
	at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.lambda$invokeRpc$0(AkkaInvocationHandler.java:227)
	at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)
	at org.apache.flink.runtime.concurrent.FutureUtils$1.onComplete(FutureUtils.java:890)
	at akka.dispatch.OnComplete.internal(Future.scala:263)
	at akka.dispatch.OnComplete.internal(Future.scala:261)
	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:191)
	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:188)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)
	at org.apache.flink.runtime.concurrent.Executors$DirectExecutionContext.execute(Executors.java:74)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:44)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:252)
	at akka.pattern.PromiseActorRef.$bang(AskSupport.scala:572)
	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:23)
	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:21)
	at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:436)
	at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:435)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)
	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: org.apache.flink.util.FlinkException: The file STDOUT is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	... 4 more
-ERROR-2021/11/05 11:24:59,948-org.apache.flink.runtime.rest.handler.AbstractHandler.handleException(AbstractHandler.java:219)-219-Unhandled exception.
org.apache.flink.util.FlinkException: The file STDOUT is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
-ERROR-2021/11/05 11:25:20,910-org.apache.flink.runtime.rest.handler.taskmanager.AbstractTaskManagerFileHandler.lambda$respondToRequest$1(AbstractTaskManagerFileHandler.java:136)-136-Failed to transfer file from TaskExecutor 73aa3074-91ac-4b1e-9951-ca1a62ed4872.
java.util.concurrent.CompletionException: org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniAccept(CompletableFuture.java:661)
	at java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:646)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)
	at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.lambda$invokeRpc$0(AkkaInvocationHandler.java:227)
	at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)
	at org.apache.flink.runtime.concurrent.FutureUtils$1.onComplete(FutureUtils.java:890)
	at akka.dispatch.OnComplete.internal(Future.scala:263)
	at akka.dispatch.OnComplete.internal(Future.scala:261)
	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:191)
	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:188)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)
	at org.apache.flink.runtime.concurrent.Executors$DirectExecutionContext.execute(Executors.java:74)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:44)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:252)
	at akka.pattern.PromiseActorRef.$bang(AskSupport.scala:572)
	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:23)
	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:21)
	at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:436)
	at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:435)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)
	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	... 4 more
-ERROR-2021/11/05 11:25:20,912-org.apache.flink.runtime.rest.handler.AbstractHandler.handleException(AbstractHandler.java:219)-219-Unhandled exception.
org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
-INFO-2021/11/05 11:25:25,320-org.apache.flink.runtime.blob.AbstractBlobCache.close(AbstractBlobCache.java:251)-251-Shutting down BLOB cache
-INFO-2021/11/05 11:25:25,321-org.apache.flink.runtime.blob.AbstractBlobCache.close(AbstractBlobCache.java:251)-251-Shutting down BLOB cache
-INFO-2021/11/05 11:25:25,321-org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager.shutdown(TaskExecutorLocalStateStoresManager.java:213)-213-Shutting down TaskExecutorLocalStateStoresManager.
-INFO-2021/11/05 11:25:25,332-org.apache.flink.runtime.blob.BlobServer.close(BlobServer.java:348)-348-Stopped BLOB server at 0.0.0.0:50626
-INFO-2021/11/05 11:25:25,333-org.apache.flink.runtime.io.disk.FileChannelManagerImpl.lambda$getFileCloser$0(FileChannelManagerImpl.java:146)-146-FileChannelManager removed spill file directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-io-9865d697-38cd-49ee-b31e-7642c542152e
-INFO-2021/11/05 11:25:25,334-org.apache.flink.runtime.io.disk.FileChannelManagerImpl.lambda$getFileCloser$0(FileChannelManagerImpl.java:146)-146-FileChannelManager removed spill file directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-netty-shuffle-fc6c325f-77a3-4554-870c-a45c35802eac
-INFO-2021/11/05 11:25:25,336-org.apache.flink.runtime.filecache.FileCache.shutdown(FileCache.java:153)-153-removed file cache directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-dist-cache-10a2dc66-dbfd-44dd-ad78-c95cf0774fb4
-INFO-2021/11/05 11:34:16,215-org.apache.flink.configuration.Configuration.loggingFallback(Configuration.java:857)-857-Config uses fallback configuration key 'rest.port' instead of key 'rest.bind-port'
-INFO-2021/11/05 11:34:16,226-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.cpu.cores' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 1.7976931348623157E308
-INFO-2021/11/05 11:34:16,229-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.memory.task.heap.size' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
-INFO-2021/11/05 11:34:16,230-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.memory.task.off-heap.size' , default: 0 bytes (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
-INFO-2021/11/05 11:34:16,231-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.memory.network.min' , default: 64 mb (fallback keys: [{key=taskmanager.network.memory.min, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
-INFO-2021/11/05 11:34:16,232-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.memory.network.max' , default: 1 gb (fallback keys: [{key=taskmanager.network.memory.max, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
-INFO-2021/11/05 11:34:16,236-org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.setConfigOptionToDefaultIfNotSet(TaskExecutorResourceUtils.java:172)-172-The configuration option Key: 'taskmanager.memory.managed.size' , default: null (fallback keys: [{key=taskmanager.memory.size, isDeprecated=true}]) required for local execution is not set, setting it to its default value 128 mb
-INFO-2021/11/05 11:34:16,266-org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:251)-251-Starting Flink Mini Cluster
-INFO-2021/11/05 11:34:16,274-org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:260)-260-Starting Metrics Registry
-INFO-2021/11/05 11:34:16,369-org.apache.flink.runtime.metrics.MetricRegistryImpl.<init>(MetricRegistryImpl.java:115)-115-No metrics reporter configured, no metrics will be exposed/reported.
-INFO-2021/11/05 11:34:16,371-org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:264)-264-Starting RPC Service(s)
-INFO-2021/11/05 11:34:16,609-org.apache.flink.runtime.clusterframework.BootstrapTools.startLocalActorSystem(BootstrapTools.java:247)-247-Trying to start local actor system
-INFO-2021/11/05 11:34:17,145-akka.event.slf4j.Slf4jLogger$$anonfun$receive$1.applyOrElse(Slf4jLogger.scala:92)-92-Slf4jLogger started
-INFO-2021/11/05 11:34:17,640-org.apache.flink.runtime.clusterframework.BootstrapTools.startActorSystem(BootstrapTools.java:278)-278-Actor system started at akka://flink
-INFO-2021/11/05 11:34:17,654-org.apache.flink.runtime.clusterframework.BootstrapTools.startLocalActorSystem(BootstrapTools.java:247)-247-Trying to start local actor system
-INFO-2021/11/05 11:34:17,667-akka.event.slf4j.Slf4jLogger$$anonfun$receive$1.applyOrElse(Slf4jLogger.scala:92)-92-Slf4jLogger started
-INFO-2021/11/05 11:34:17,742-org.apache.flink.runtime.clusterframework.BootstrapTools.startActorSystem(BootstrapTools.java:278)-278-Actor system started at akka://flink-metrics
-INFO-2021/11/05 11:34:17,756-org.apache.flink.runtime.rpc.akka.AkkaRpcService.startServer(AkkaRpcService.java:225)-225-Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
-INFO-2021/11/05 11:34:17,845-org.apache.flink.runtime.minicluster.MiniCluster.createHighAvailabilityServices(MiniCluster.java:432)-432-Starting high-availability services
-INFO-2021/11/05 11:34:17,859-org.apache.flink.runtime.blob.BlobServer.<init>(BlobServer.java:143)-143-Created BLOB server storage directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/blobStore-bec02dd2-af7a-4cda-982a-c0cf8d53c166
-INFO-2021/11/05 11:34:17,870-org.apache.flink.runtime.blob.BlobServer.<init>(BlobServer.java:207)-207-Started BLOB server at 0.0.0.0:63728 - max concurrent requests: 50 - max backlog: 1000
-INFO-2021/11/05 11:34:17,877-org.apache.flink.runtime.blob.AbstractBlobCache.<init>(AbstractBlobCache.java:107)-107-Created BLOB cache storage directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/blobStore-d664961e-b212-458c-b43a-cff552d9fd64
-INFO-2021/11/05 11:34:17,879-org.apache.flink.runtime.blob.AbstractBlobCache.<init>(AbstractBlobCache.java:107)-107-Created BLOB cache storage directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/blobStore-55cc2b76-6231-4564-84f5-cbe030e3c85e
-INFO-2021/11/05 11:34:17,881-org.apache.flink.runtime.minicluster.MiniCluster.startTaskManagers(MiniCluster.java:519)-519-Starting 1 TaskManger(s)
-INFO-2021/11/05 11:34:17,884-org.apache.flink.runtime.taskexecutor.TaskManagerRunner.startTaskManager(TaskManagerRunner.java:351)-351-Starting TaskManager with ResourceID: fa3d5091-a801-4fe1-80f7-2725b020afc8
-INFO-2021/11/05 11:34:17,934-org.apache.flink.runtime.taskexecutor.TaskManagerServices.checkTempDirs(TaskManagerServices.java:405)-405-Temporary file directory '/var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T': total 465 GB, usable 327 GB (70.32% usable)
-INFO-2021/11/05 11:34:17,938-org.apache.flink.runtime.io.disk.FileChannelManagerImpl.createFiles(FileChannelManagerImpl.java:97)-97-FileChannelManager uses directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-io-12cec0a4-beaf-438d-b890-193eb26fcbbb for spill files.
-INFO-2021/11/05 11:34:17,946-org.apache.flink.runtime.io.disk.FileChannelManagerImpl.createFiles(FileChannelManagerImpl.java:97)-97-FileChannelManager uses directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-netty-shuffle-1d22b6af-5c03-4d80-bf49-544d343e42d0 for spill files.
-INFO-2021/11/05 11:34:17,991-org.apache.flink.runtime.io.network.buffer.NetworkBufferPool.<init>(NetworkBufferPool.java:145)-145-Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
-INFO-2021/11/05 11:34:17,997-org.apache.flink.runtime.io.network.NettyShuffleEnvironment.start(NettyShuffleEnvironment.java:293)-293-Starting the network environment and its components.
-INFO-2021/11/05 11:34:17,999-org.apache.flink.runtime.taskexecutor.KvStateService.start(KvStateService.java:89)-89-Starting the kvState service and its components.
-INFO-2021/11/05 11:34:18,024-org.apache.flink.runtime.rpc.akka.AkkaRpcService.startServer(AkkaRpcService.java:225)-225-Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
-INFO-2021/11/05 11:34:18,036-org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService.start(DefaultJobLeaderService.java:116)-116-Start job leader service.
-INFO-2021/11/05 11:34:18,037-org.apache.flink.runtime.filecache.FileCache.<init>(FileCache.java:107)-107-User file cache uses directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-dist-cache-26a1315d-bd0c-4722-9f48-e190ba69eaf0
-INFO-2021/11/05 11:34:18,058-org.apache.flink.configuration.Configuration.loggingFallback(Configuration.java:857)-857-Config uses fallback configuration key 'rest.port' instead of key 'rest.bind-port'
-INFO-2021/11/05 11:34:18,099-org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:140)-140-Starting rest endpoint.
-WARN-2021/11/05 11:34:18,476-org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation.find(WebMonitorUtils.java:91)-91-Log file environment variable 'log.file' is not set.
-WARN-2021/11/05 11:34:18,477-org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation.find(WebMonitorUtils.java:97)-97-JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
-INFO-2021/11/05 11:34:18,770-org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:236)-236-Rest endpoint listening at localhost:8081
-INFO-2021/11/05 11:34:18,772-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.updateLeader(EmbeddedLeaderService.java:302)-302-Proposing leadership to contender http://localhost:8081
-INFO-2021/11/05 11:34:18,777-org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.startInternal(WebMonitorEndpoint.java:756)-756-Web frontend listening at http://localhost:8081.
-INFO-2021/11/05 11:34:18,777-org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.grantLeadership(WebMonitorEndpoint.java:812)-812-http://localhost:8081 was granted leadership with leaderSessionID=097e5ba3-964d-4261-8b9a-2157c9559a35
-INFO-2021/11/05 11:34:18,777-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.confirmLeader(EmbeddedLeaderService.java:252)-252-Received confirmation of leadership for leader http://localhost:8081 , session=097e5ba3-964d-4261-8b9a-2157c9559a35
-INFO-2021/11/05 11:34:18,796-org.apache.flink.runtime.rpc.akka.AkkaRpcService.startServer(AkkaRpcService.java:225)-225-Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
-INFO-2021/11/05 11:34:18,816-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.updateLeader(EmbeddedLeaderService.java:302)-302-Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
-INFO-2021/11/05 11:34:18,817-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.updateLeader(EmbeddedLeaderService.java:302)-302-Proposing leadership to contender LeaderContender: StandaloneResourceManager
-INFO-2021/11/05 11:34:18,823-org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:372)-372-Flink Mini Cluster started successfully
-INFO-2021/11/05 11:34:18,824-org.apache.flink.runtime.resourcemanager.ResourceManager.tryAcceptLeadership(ResourceManager.java:984)-984-ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token 8c9ff295b082f27190141414111a46d0
-INFO-2021/11/05 11:34:18,825-org.apache.flink.runtime.dispatcher.runner.AbstractDispatcherLeaderProcess.startInternal(AbstractDispatcherLeaderProcess.java:101)-101-Start SessionDispatcherLeaderProcess.
-INFO-2021/11/05 11:34:18,827-org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess.recoverJobs(SessionDispatcherLeaderProcess.java:120)-120-Recover all persisted job graphs.
-INFO-2021/11/05 11:34:18,828-org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess.recoverJobs(SessionDispatcherLeaderProcess.java:128)-128-Successfully recovered 0 persisted job graphs.
-INFO-2021/11/05 11:34:18,829-org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl.start(SlotManagerImpl.java:279)-279-Starting the SlotManager.
-INFO-2021/11/05 11:34:18,833-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.confirmLeader(EmbeddedLeaderService.java:252)-252-Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=90141414-111a-46d0-8c9f-f295b082f271
-INFO-2021/11/05 11:34:18,835-org.apache.flink.runtime.rpc.akka.AkkaRpcService.startServer(AkkaRpcService.java:225)-225-Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
-INFO-2021/11/05 11:34:18,836-org.apache.flink.runtime.taskexecutor.TaskExecutor.connectToResourceManager(TaskExecutor.java:1123)-1123-Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(8c9ff295b082f27190141414111a46d0).
-INFO-2021/11/05 11:34:18,847-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.confirmLeader(EmbeddedLeaderService.java:252)-252-Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=17e983de-2cfc-4a95-aeef-7932c0f217c1
-INFO-2021/11/05 11:34:18,868-org.apache.flink.runtime.registration.RetryingRegistration.lambda$startRegistration$0(RetryingRegistration.java:155)-155-Resolved ResourceManager address, beginning registration
-INFO-2021/11/05 11:34:18,879-org.apache.flink.runtime.resourcemanager.ResourceManager.registerTaskExecutorInternal(ResourceManager.java:781)-781-Registering TaskManager with ResourceID fa3d5091-a801-4fe1-80f7-2725b020afc8 (akka://flink/user/rpc/taskmanager_0) at ResourceManager
-INFO-2021/11/05 11:34:18,882-org.apache.flink.runtime.dispatcher.Dispatcher.submitJob(Dispatcher.java:275)-275-Received JobGraph submission bea4d5783e0f71baf279851d59e847dc (this is kafka_test).
-INFO-2021/11/05 11:34:18,882-org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection.onRegistrationSuccess(TaskExecutorToResourceManagerConnection.java:84)-84-Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 734b3655c820c5df4172c6909e9cb2be.
-INFO-2021/11/05 11:34:18,883-org.apache.flink.runtime.dispatcher.Dispatcher.internalSubmitJob(Dispatcher.java:332)-332-Submitting job bea4d5783e0f71baf279851d59e847dc (this is kafka_test).
-INFO-2021/11/05 11:34:18,909-org.apache.flink.runtime.rpc.akka.AkkaRpcService.startServer(AkkaRpcService.java:225)-225-Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
-INFO-2021/11/05 11:34:18,918-org.apache.flink.runtime.jobmaster.JobMaster.<init>(JobMaster.java:248)-248-Initializing job this is kafka_test (bea4d5783e0f71baf279851d59e847dc).
-INFO-2021/11/05 11:34:18,937-org.apache.flink.runtime.scheduler.DefaultSchedulerFactory.createInstance(DefaultSchedulerFactory.java:80)-80-Using restart back off time strategy NoRestartBackoffTimeStrategy for this is kafka_test (bea4d5783e0f71baf279851d59e847dc).
-INFO-2021/11/05 11:34:19,058-org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder.buildGraph(ExecutionGraphBuilder.java:202)-202-Running initialization on master for job this is kafka_test (bea4d5783e0f71baf279851d59e847dc).
-INFO-2021/11/05 11:34:19,058-org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder.buildGraph(ExecutionGraphBuilder.java:220)-220-Successfully ran initialization on master in 0 ms.
-INFO-2021/11/05 11:34:19,076-org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology.initializePipelinedRegions(DefaultExecutionTopology.java:111)-111-Built 8 pipelined regions in 0 ms
-INFO-2021/11/05 11:34:19,087-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:34:19,101-org.apache.flink.runtime.scheduler.DefaultScheduler.<init>(DefaultScheduler.java:148)-148-Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@354e6ae0 for this is kafka_test (bea4d5783e0f71baf279851d59e847dc).
-INFO-2021/11/05 11:34:19,104-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.updateLeader(EmbeddedLeaderService.java:302)-302-Proposing leadership to contender akka://flink/user/rpc/jobmanager_3
-INFO-2021/11/05 11:34:19,105-org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl.startJobMaster(JobManagerRunnerImpl.java:304)-304-JobManager runner for job this is kafka_test (bea4d5783e0f71baf279851d59e847dc) was granted leadership with session id 2b16017c-fff4-4844-8834-c4b714733b81 at akka://flink/user/rpc/jobmanager_3.
-INFO-2021/11/05 11:34:19,109-org.apache.flink.runtime.jobmaster.JobMaster.startJobExecution(JobMaster.java:758)-758-Starting execution of job this is kafka_test (bea4d5783e0f71baf279851d59e847dc) under job master id 8834c4b714733b812b16017cfff44844.
-INFO-2021/11/05 11:34:19,111-org.apache.flink.runtime.scheduler.DefaultScheduler.startSchedulingInternal(DefaultScheduler.java:171)-171-Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.EagerSchedulingStrategy]
-INFO-2021/11/05 11:34:19,111-org.apache.flink.runtime.executiongraph.ExecutionGraph.transitionState(ExecutionGraph.java:1240)-1240-Job this is kafka_test (bea4d5783e0f71baf279851d59e847dc) switched from state CREATED to RUNNING.
-INFO-2021/11/05 11:34:19,119-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (1/8) (875a62366077ce623d6d63810c058ac6) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:34:19,119-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (2/8) (a592f1699513e7347b4ff132b2612508) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:34:19,119-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (3/8) (43fbf2499fe9dc50bbbd78b2ff02aa39) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:34:19,120-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (4/8) (6188cc42e51cff13f3b7184259d7b26e) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:34:19,120-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (5/8) (2c9af3731fc0fb1d59782e8f87a1522b) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:34:19,120-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (6/8) (895497b4abfbf2ff28b64b5dba90e83e) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:34:19,120-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (7/8) (9cb8bfdab6e13433fd5d0663c98374c8) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:34:19,120-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (8/8) (3f9b5538eeaeb64c79f5e07423b2cd9b) switched from CREATED to SCHEDULED.
-INFO-2021/11/05 11:34:19,133-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e8ee104d886317ff1ad2711590198e7f}]
-INFO-2021/11/05 11:34:19,137-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{6d862382c2f489088619ae7cfa6e72e2}]
-INFO-2021/11/05 11:34:19,138-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{506d22870aee0dcf1ffa89190058cee2}]
-INFO-2021/11/05 11:34:19,138-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{0d5e0454cbb6b59f3632a57705355b4d}]
-INFO-2021/11/05 11:34:19,138-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2e8a5ee4bc18e2aaa2f4b818e912da4a}]
-INFO-2021/11/05 11:34:19,139-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{59332a786cd3b9679bb197a2a3325c15}]
-INFO-2021/11/05 11:34:19,139-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2e33e322390c312b3df87747358d26fc}]
-INFO-2021/11/05 11:34:19,140-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.stashRequestWaitingForResourceManager(SlotPoolImpl.java:372)-372-Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{4685b497eb9002071d79d571f512de99}]
-INFO-2021/11/05 11:34:19,142-org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.confirmLeader(EmbeddedLeaderService.java:252)-252-Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=2b16017c-fff4-4844-8834-c4b714733b81
-INFO-2021/11/05 11:34:19,142-org.apache.flink.runtime.jobmaster.JobMaster.connectToResourceManager(JobMaster.java:984)-984-Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(8c9ff295b082f27190141414111a46d0)
-INFO-2021/11/05 11:34:19,144-org.apache.flink.runtime.registration.RetryingRegistration.lambda$startRegistration$0(RetryingRegistration.java:155)-155-Resolved ResourceManager address, beginning registration
-INFO-2021/11/05 11:34:19,146-org.apache.flink.runtime.resourcemanager.ResourceManager.registerJobManager(ResourceManager.java:317)-317-Registering job manager 8834c4b714733b812b16017cfff44844@akka://flink/user/rpc/jobmanager_3 for job bea4d5783e0f71baf279851d59e847dc.
-INFO-2021/11/05 11:34:19,151-org.apache.flink.runtime.resourcemanager.ResourceManager.registerJobMasterInternal(ResourceManager.java:727)-727-Registered job manager 8834c4b714733b812b16017cfff44844@akka://flink/user/rpc/jobmanager_3 for job bea4d5783e0f71baf279851d59e847dc.
-INFO-2021/11/05 11:34:19,153-org.apache.flink.runtime.jobmaster.JobMaster.establishResourceManagerConnection(JobMaster.java:1006)-1006-JobManager successfully registered at ResourceManager, leader id: 8c9ff295b082f27190141414111a46d0.
-INFO-2021/11/05 11:34:19,154-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{e8ee104d886317ff1ad2711590198e7f}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:34:19,155-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job bea4d5783e0f71baf279851d59e847dc with allocation id 7383b0e23d8eeba5ae32081a0fd0212a.
-INFO-2021/11/05 11:34:19,156-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{6d862382c2f489088619ae7cfa6e72e2}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:34:19,156-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{506d22870aee0dcf1ffa89190058cee2}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:34:19,157-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{0d5e0454cbb6b59f3632a57705355b4d}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:34:19,158-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{2e8a5ee4bc18e2aaa2f4b818e912da4a}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:34:19,158-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{59332a786cd3b9679bb197a2a3325c15}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:34:19,159-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{2e33e322390c312b3df87747358d26fc}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:34:19,159-org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl.requestSlotFromResourceManager(SlotPoolImpl.java:322)-322-Requesting new slot [SlotRequestId{4685b497eb9002071d79d571f512de99}] and profile ResourceProfile{UNKNOWN} from resource manager.
-INFO-2021/11/05 11:34:19,159-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 7383b0e23d8eeba5ae32081a0fd0212a for job bea4d5783e0f71baf279851d59e847dc from resource manager with leader id 8c9ff295b082f27190141414111a46d0.
-INFO-2021/11/05 11:34:19,161-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job bea4d5783e0f71baf279851d59e847dc with allocation id 50909c3bea07ebe2aa22eab7928fc652.
-INFO-2021/11/05 11:34:19,162-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job bea4d5783e0f71baf279851d59e847dc with allocation id 9a7eaf6fffaa54593ee73c65583d35df.
-INFO-2021/11/05 11:34:19,163-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job bea4d5783e0f71baf279851d59e847dc with allocation id 2e0d38313daf33134c205ee9dd0ef8cf.
-INFO-2021/11/05 11:34:19,164-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job bea4d5783e0f71baf279851d59e847dc with allocation id aafcad67017e12d6e91da4fd8fe43b0e.
-INFO-2021/11/05 11:34:19,164-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job bea4d5783e0f71baf279851d59e847dc with allocation id 3126a630817ebfdc54d6caea777d8150.
-INFO-2021/11/05 11:34:19,165-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 7383b0e23d8eeba5ae32081a0fd0212a.
-INFO-2021/11/05 11:34:19,165-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job bea4d5783e0f71baf279851d59e847dc with allocation id 246fbd2d07f623c6d082d56f032a6820.
-INFO-2021/11/05 11:34:19,166-org.apache.flink.runtime.resourcemanager.ResourceManager.requestSlot(ResourceManager.java:451)-451-Request slot with profile ResourceProfile{UNKNOWN} for job bea4d5783e0f71baf279851d59e847dc with allocation id 9edde3f60b406cd06b837ae683abc039.
-INFO-2021/11/05 11:34:19,167-org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService.addJob(DefaultJobLeaderService.java:172)-172-Add job bea4d5783e0f71baf279851d59e847dc for job leader monitoring.
-INFO-2021/11/05 11:34:19,169-org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener.openRpcConnectionTo(DefaultJobLeaderService.java:314)-314-Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id 2b16017c-fff4-4844-8834-c4b714733b81.
-INFO-2021/11/05 11:34:19,169-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 50909c3bea07ebe2aa22eab7928fc652 for job bea4d5783e0f71baf279851d59e847dc from resource manager with leader id 8c9ff295b082f27190141414111a46d0.
-INFO-2021/11/05 11:34:19,169-org.apache.flink.runtime.registration.RetryingRegistration.lambda$startRegistration$0(RetryingRegistration.java:155)-155-Resolved JobManager address, beginning registration
-INFO-2021/11/05 11:34:19,169-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 50909c3bea07ebe2aa22eab7928fc652.
-INFO-2021/11/05 11:34:19,170-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 9a7eaf6fffaa54593ee73c65583d35df for job bea4d5783e0f71baf279851d59e847dc from resource manager with leader id 8c9ff295b082f27190141414111a46d0.
-INFO-2021/11/05 11:34:19,170-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 9a7eaf6fffaa54593ee73c65583d35df.
-INFO-2021/11/05 11:34:19,171-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 2e0d38313daf33134c205ee9dd0ef8cf for job bea4d5783e0f71baf279851d59e847dc from resource manager with leader id 8c9ff295b082f27190141414111a46d0.
-INFO-2021/11/05 11:34:19,172-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 2e0d38313daf33134c205ee9dd0ef8cf.
-INFO-2021/11/05 11:34:19,172-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request aafcad67017e12d6e91da4fd8fe43b0e for job bea4d5783e0f71baf279851d59e847dc from resource manager with leader id 8c9ff295b082f27190141414111a46d0.
-INFO-2021/11/05 11:34:19,173-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for aafcad67017e12d6e91da4fd8fe43b0e.
-INFO-2021/11/05 11:34:19,173-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 3126a630817ebfdc54d6caea777d8150 for job bea4d5783e0f71baf279851d59e847dc from resource manager with leader id 8c9ff295b082f27190141414111a46d0.
-INFO-2021/11/05 11:34:19,174-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 3126a630817ebfdc54d6caea777d8150.
-INFO-2021/11/05 11:34:19,174-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 246fbd2d07f623c6d082d56f032a6820 for job bea4d5783e0f71baf279851d59e847dc from resource manager with leader id 8c9ff295b082f27190141414111a46d0.
-INFO-2021/11/05 11:34:19,174-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 246fbd2d07f623c6d082d56f032a6820.
-INFO-2021/11/05 11:34:19,175-org.apache.flink.runtime.taskexecutor.TaskExecutor.requestSlot(TaskExecutor.java:903)-903-Receive slot request 9edde3f60b406cd06b837ae683abc039 for job bea4d5783e0f71baf279851d59e847dc from resource manager with leader id 8c9ff295b082f27190141414111a46d0.
-INFO-2021/11/05 11:34:19,175-org.apache.flink.runtime.taskexecutor.TaskExecutor.allocateSlot(TaskExecutor.java:971)-971-Allocated slot for 9edde3f60b406cd06b837ae683abc039.
-INFO-2021/11/05 11:34:19,177-org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection.onRegistrationSuccess(DefaultJobLeaderService.java:369)-369-Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job bea4d5783e0f71baf279851d59e847dc.
-INFO-2021/11/05 11:34:19,178-org.apache.flink.runtime.taskexecutor.TaskExecutor.establishJobManagerConnection(TaskExecutor.java:1372)-1372-Establish JobManager connection for job bea4d5783e0f71baf279851d59e847dc.
-INFO-2021/11/05 11:34:19,183-org.apache.flink.runtime.taskexecutor.TaskExecutor.internalOfferSlotsToJobManager(TaskExecutor.java:1271)-1271-Offer reserved slots to the leader of job bea4d5783e0f71baf279851d59e847dc.
-INFO-2021/11/05 11:34:19,188-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (1/8) (875a62366077ce623d6d63810c058ac6) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:34:19,189-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (1/8) (attempt #0) to fa3d5091-a801-4fe1-80f7-2725b020afc8 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:34:19,194-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (2/8) (a592f1699513e7347b4ff132b2612508) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:34:19,194-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (2/8) (attempt #0) to fa3d5091-a801-4fe1-80f7-2725b020afc8 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:34:19,194-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 7383b0e23d8eeba5ae32081a0fd0212a.
-INFO-2021/11/05 11:34:19,194-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (3/8) (43fbf2499fe9dc50bbbd78b2ff02aa39) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:34:19,195-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (3/8) (attempt #0) to fa3d5091-a801-4fe1-80f7-2725b020afc8 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:34:19,195-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (4/8) (6188cc42e51cff13f3b7184259d7b26e) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:34:19,196-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (4/8) (attempt #0) to fa3d5091-a801-4fe1-80f7-2725b020afc8 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:34:19,196-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (5/8) (2c9af3731fc0fb1d59782e8f87a1522b) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:34:19,196-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (5/8) (attempt #0) to fa3d5091-a801-4fe1-80f7-2725b020afc8 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:34:19,197-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (6/8) (895497b4abfbf2ff28b64b5dba90e83e) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:34:19,197-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (6/8) (attempt #0) to fa3d5091-a801-4fe1-80f7-2725b020afc8 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:34:19,197-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (7/8) (9cb8bfdab6e13433fd5d0663c98374c8) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:34:19,198-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (7/8) (attempt #0) to fa3d5091-a801-4fe1-80f7-2725b020afc8 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:34:19,198-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (8/8) (3f9b5538eeaeb64c79f5e07423b2cd9b) switched from SCHEDULED to DEPLOYING.
-INFO-2021/11/05 11:34:19,198-org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:730)-730-Deploying Source: Custom Source -> Sink: Print to Std. Out (8/8) (attempt #0) to fa3d5091-a801-4fe1-80f7-2725b020afc8 @ localhost (dataPort=-1)
-INFO-2021/11/05 11:34:19,221-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (1/8).
-INFO-2021/11/05 11:34:19,222-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (1/8) (875a62366077ce623d6d63810c058ac6) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:34:19,225-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 50909c3bea07ebe2aa22eab7928fc652.
-INFO-2021/11/05 11:34:19,227-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (1/8) (875a62366077ce623d6d63810c058ac6) [DEPLOYING].
-INFO-2021/11/05 11:34:19,228-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (2/8).
-INFO-2021/11/05 11:34:19,229-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (2/8) (a592f1699513e7347b4ff132b2612508) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:34:19,229-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 9a7eaf6fffaa54593ee73c65583d35df.
-INFO-2021/11/05 11:34:19,229-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (1/8) (875a62366077ce623d6d63810c058ac6) [DEPLOYING].
-INFO-2021/11/05 11:34:19,229-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (2/8) (a592f1699513e7347b4ff132b2612508) [DEPLOYING].
-INFO-2021/11/05 11:34:19,231-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (2/8) (a592f1699513e7347b4ff132b2612508) [DEPLOYING].
-INFO-2021/11/05 11:34:19,232-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (3/8).
-INFO-2021/11/05 11:34:19,232-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (3/8) (43fbf2499fe9dc50bbbd78b2ff02aa39) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:34:19,232-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 2e0d38313daf33134c205ee9dd0ef8cf.
-INFO-2021/11/05 11:34:19,232-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (3/8) (43fbf2499fe9dc50bbbd78b2ff02aa39) [DEPLOYING].
-INFO-2021/11/05 11:34:19,234-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (3/8) (43fbf2499fe9dc50bbbd78b2ff02aa39) [DEPLOYING].
-INFO-2021/11/05 11:34:19,235-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (4/8).
-INFO-2021/11/05 11:34:19,236-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (4/8) (6188cc42e51cff13f3b7184259d7b26e) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:34:19,236-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot aafcad67017e12d6e91da4fd8fe43b0e.
-INFO-2021/11/05 11:34:19,236-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (4/8) (6188cc42e51cff13f3b7184259d7b26e) [DEPLOYING].
-INFO-2021/11/05 11:34:19,237-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (4/8) (6188cc42e51cff13f3b7184259d7b26e) [DEPLOYING].
-INFO-2021/11/05 11:34:19,239-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (5/8).
-INFO-2021/11/05 11:34:19,239-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (5/8) (2c9af3731fc0fb1d59782e8f87a1522b) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:34:19,240-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (5/8) (2c9af3731fc0fb1d59782e8f87a1522b) [DEPLOYING].
-INFO-2021/11/05 11:34:19,240-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 3126a630817ebfdc54d6caea777d8150.
-INFO-2021/11/05 11:34:19,241-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (5/8) (2c9af3731fc0fb1d59782e8f87a1522b) [DEPLOYING].
-INFO-2021/11/05 11:34:19,243-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (6/8).
-INFO-2021/11/05 11:34:19,246-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 246fbd2d07f623c6d082d56f032a6820.
-INFO-2021/11/05 11:34:19,246-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (6/8) (895497b4abfbf2ff28b64b5dba90e83e) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:34:19,247-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (6/8) (895497b4abfbf2ff28b64b5dba90e83e) [DEPLOYING].
-INFO-2021/11/05 11:34:19,248-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (6/8) (895497b4abfbf2ff28b64b5dba90e83e) [DEPLOYING].
-INFO-2021/11/05 11:34:19,249-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (7/8).
-INFO-2021/11/05 11:34:19,249-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:34:19,249-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (7/8) (9cb8bfdab6e13433fd5d0663c98374c8) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:34:19,249-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:34:19,249-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:34:19,249-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:34:19,249-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:34:19,249-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:34:19,250-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 9a7eaf6fffaa54593ee73c65583d35df.
-INFO-2021/11/05 11:34:19,250-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (7/8) (9cb8bfdab6e13433fd5d0663c98374c8) [DEPLOYING].
-INFO-2021/11/05 11:34:19,251-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 3126a630817ebfdc54d6caea777d8150.
-INFO-2021/11/05 11:34:19,251-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 246fbd2d07f623c6d082d56f032a6820.
-INFO-2021/11/05 11:34:19,251-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 50909c3bea07ebe2aa22eab7928fc652.
-INFO-2021/11/05 11:34:19,252-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 7383b0e23d8eeba5ae32081a0fd0212a.
-INFO-2021/11/05 11:34:19,252-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 2e0d38313daf33134c205ee9dd0ef8cf.
-INFO-2021/11/05 11:34:19,252-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (7/8) (9cb8bfdab6e13433fd5d0663c98374c8) [DEPLOYING].
-INFO-2021/11/05 11:34:19,252-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot aafcad67017e12d6e91da4fd8fe43b0e.
-INFO-2021/11/05 11:34:19,252-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 9edde3f60b406cd06b837ae683abc039.
-INFO-2021/11/05 11:34:19,253-org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.markExistingSlotActive(TaskSlotTableImpl.java:332)-332-Activate slot 9edde3f60b406cd06b837ae683abc039.
-INFO-2021/11/05 11:34:19,253-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:34:19,255-org.apache.flink.runtime.taskexecutor.TaskExecutor.submitTask(TaskExecutor.java:646)-646-Received task Source: Custom Source -> Sink: Print to Std. Out (8/8).
-INFO-2021/11/05 11:34:19,256-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (8/8) (3f9b5538eeaeb64c79f5e07423b2cd9b) switched from CREATED to DEPLOYING.
-INFO-2021/11/05 11:34:19,256-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:607)-607-Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (8/8) (3f9b5538eeaeb64c79f5e07423b2cd9b) [DEPLOYING].
-INFO-2021/11/05 11:34:19,258-org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:633)-633-Registering task at network: Source: Custom Source -> Sink: Print to Std. Out (8/8) (3f9b5538eeaeb64c79f5e07423b2cd9b) [DEPLOYING].
-INFO-2021/11/05 11:34:19,258-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (4/8) (6188cc42e51cff13f3b7184259d7b26e) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,259-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (5/8) (2c9af3731fc0fb1d59782e8f87a1522b) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,258-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (3/8) (43fbf2499fe9dc50bbbd78b2ff02aa39) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,258-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (6/8) (895497b4abfbf2ff28b64b5dba90e83e) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,260-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (4/8) (6188cc42e51cff13f3b7184259d7b26e) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,258-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (2/8) (a592f1699513e7347b4ff132b2612508) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,262-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (5/8) (2c9af3731fc0fb1d59782e8f87a1522b) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,262-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (3/8) (43fbf2499fe9dc50bbbd78b2ff02aa39) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,258-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (7/8) (9cb8bfdab6e13433fd5d0663c98374c8) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,258-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (1/8) (875a62366077ce623d6d63810c058ac6) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,263-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (6/8) (895497b4abfbf2ff28b64b5dba90e83e) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,259-org.apache.flink.runtime.state.StateBackendLoader.fromApplicationOrConfigOrDefault(StateBackendLoader.java:228)-228-No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
-INFO-2021/11/05 11:34:19,264-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (2/8) (a592f1699513e7347b4ff132b2612508) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,264-org.apache.flink.runtime.taskmanager.Task.transitionState(Task.java:968)-968-Source: Custom Source -> Sink: Print to Std. Out (8/8) (3f9b5538eeaeb64c79f5e07423b2cd9b) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,264-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (7/8) (9cb8bfdab6e13433fd5d0663c98374c8) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,265-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (1/8) (875a62366077ce623d6d63810c058ac6) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,265-org.apache.flink.runtime.executiongraph.Execution.transitionState(Execution.java:1588)-1588-Source: Custom Source -> Sink: Print to Std. Out (8/8) (3f9b5538eeaeb64c79f5e07423b2cd9b) switched from DEPLOYING to RUNNING.
-INFO-2021/11/05 11:34:19,338-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 1 has no restore state.
-INFO-2021/11/05 11:34:19,338-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 3 has no restore state.
-INFO-2021/11/05 11:34:19,338-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 0 has no restore state.
-INFO-2021/11/05 11:34:19,338-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 5 has no restore state.
-INFO-2021/11/05 11:34:19,338-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 7 has no restore state.
-INFO-2021/11/05 11:34:19,338-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 6 has no restore state.
-INFO-2021/11/05 11:34:19,338-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 2 has no restore state.
-INFO-2021/11/05 11:34:19,338-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.initializeState(FlinkKafkaConsumerBase.java:910)-910-Consumer subtask 4 has no restore state.
-INFO-2021/11/05 11:34:19,360-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:34:19,360-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:34:19,360-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:34:19,360-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:34:19,360-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:34:19,360-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:34:19,360-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:34:19,360-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-WARN-2021/11/05 11:34:19,441-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:34:19,441-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:34:19,442-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:34:19,442-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:34:19,442-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:34:19,443-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:34:19,442-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:34:19,443-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:34:19,443-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:34:19,444-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:34:19,444-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:34:19,445-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:34:19,445-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:34:19,445-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:34:19,446-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:34:19,446-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:34:19,446-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:34:19,446-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:34:19,447-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:34:19,447-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:34:19,447-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:34:19,447-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:34:19,448-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:34:19,448-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:34:19,643-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 4 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=5}]
-INFO-2021/11/05 11:34:19,643-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 0 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=1}]
-INFO-2021/11/05 11:34:19,643-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 7 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=0}]
-INFO-2021/11/05 11:34:19,643-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 2 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=3}]
-INFO-2021/11/05 11:34:19,643-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 5 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=6}]
-INFO-2021/11/05 11:34:19,643-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=2}]
-INFO-2021/11/05 11:34:19,643-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 3 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=4}]
-INFO-2021/11/05 11:34:19,643-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.open(FlinkKafkaConsumerBase.java:684)-684-Consumer subtask 6 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='r_source01', partition=7}]
-INFO-2021/11/05 11:34:19,649-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=2}=-915623761773}.
-INFO-2021/11/05 11:34:19,649-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 7 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=0}=-915623761773}.
-INFO-2021/11/05 11:34:19,649-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 3 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=4}=-915623761773}.
-INFO-2021/11/05 11:34:19,649-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 5 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=6}=-915623761773}.
-INFO-2021/11/05 11:34:19,649-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 4 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=5}=-915623761773}.
-INFO-2021/11/05 11:34:19,649-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=1}=-915623761773}.
-INFO-2021/11/05 11:34:19,649-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 6 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=7}=-915623761773}.
-INFO-2021/11/05 11:34:19,649-org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:729)-729-Consumer subtask 2 creating fetcher with offsets {KafkaTopicPartition{topic='r_source01', partition=3}=-915623761773}.
-INFO-2021/11/05 11:34:19,660-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:34:19,661-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:34:19,661-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:34:19,661-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:34:19,660-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:34:19,662-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:34:19,661-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-INFO-2021/11/05 11:34:19,661-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.0.12.254:18108]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

-WARN-2021/11/05 11:34:19,672-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:34:19,672-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:34:19,673-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-WARN-2021/11/05 11:34:19,674-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:34:19,675-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:34:19,675-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-WARN-2021/11/05 11:34:19,674-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:34:19,676-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:34:19,677-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-WARN-2021/11/05 11:34:19,677-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:34:19,675-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:34:19,677-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:34:19,678-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-WARN-2021/11/05 11:34:19,676-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-WARN-2021/11/05 11:34:19,676-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:34:19,679-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-WARN-2021/11/05 11:34:19,678-org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:231)-231-The configuration 'zookeeper.connect' was supplied but isn't a known config.
-INFO-2021/11/05 11:34:19,679-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:34:19,680-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:34:19,680-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:34:19,680-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:34:19,681-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:34:19,681-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 11:34:19,681-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 11:34:19,743-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:34:19,743-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:34:19,743-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:34:19,743-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:34:19,743-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:34:19,743-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:34:19,746-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-INFO-2021/11/05 11:34:19,746-org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:607)-607-Discovered coordinator 10.0.12.254:18108 (id: 2147483646 rack: null) for group .
-ERROR-2021/11/05 11:35:32,282-org.apache.flink.runtime.rest.handler.AbstractHandler.handleException(AbstractHandler.java:219)-219-Unhandled exception.
org.apache.flink.runtime.resourcemanager.exceptions.UnknownTaskExecutorException: No TaskExecutor registered under 73aa3074-91ac-4b1e-9951-ca1a62ed4872.
	at org.apache.flink.runtime.resourcemanager.ResourceManager.requestTaskManagerInfo(ResourceManager.java:560)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:74)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
-ERROR-2021/11/05 11:35:46,210-org.apache.flink.runtime.rest.handler.taskmanager.AbstractTaskManagerFileHandler.lambda$respondToRequest$1(AbstractTaskManagerFileHandler.java:136)-136-Failed to transfer file from TaskExecutor fa3d5091-a801-4fe1-80f7-2725b020afc8.
java.util.concurrent.CompletionException: org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniAccept(CompletableFuture.java:661)
	at java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:646)
	at java.util.concurrent.CompletableFuture.uniAcceptStage(CompletableFuture.java:686)
	at java.util.concurrent.CompletableFuture.thenAcceptAsync(CompletableFuture.java:2019)
	at org.apache.flink.runtime.rest.handler.taskmanager.AbstractTaskManagerFileHandler.respondToRequest(AbstractTaskManagerFileHandler.java:113)
	at org.apache.flink.runtime.rest.handler.AbstractHandler.respondAsLeader(AbstractHandler.java:172)
	at org.apache.flink.runtime.rest.handler.LeaderRetrievalHandler.lambda$channelRead0$0(LeaderRetrievalHandler.java:81)
	at java.util.Optional.ifPresent(Optional.java:159)
	at org.apache.flink.util.OptionalConsumer.ifPresent(OptionalConsumer.java:46)
	at org.apache.flink.runtime.rest.handler.LeaderRetrievalHandler.channelRead0(LeaderRetrievalHandler.java:78)
	at org.apache.flink.runtime.rest.handler.LeaderRetrievalHandler.channelRead0(LeaderRetrievalHandler.java:49)
	at org.apache.flink.shaded.netty4.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at org.apache.flink.runtime.rest.handler.router.RouterHandler.routed(RouterHandler.java:110)
	at org.apache.flink.runtime.rest.handler.router.RouterHandler.channelRead0(RouterHandler.java:89)
	at org.apache.flink.runtime.rest.handler.router.RouterHandler.channelRead0(RouterHandler.java:54)
	at org.apache.flink.shaded.netty4.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at org.apache.flink.runtime.rest.FileUploadHandler.channelRead0(FileUploadHandler.java:174)
	at org.apache.flink.runtime.rest.FileUploadHandler.channelRead0(FileUploadHandler.java:68)
	at org.apache.flink.shaded.netty4.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at org.apache.flink.shaded.netty4.io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:438)
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:328)
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:302)
	at org.apache.flink.shaded.netty4.io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:253)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at org.apache.flink.shaded.netty4.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1421)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at org.apache.flink.shaded.netty4.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697)
	at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632)
	at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549)
	at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511)
	at org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918)
	at org.apache.flink.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
-ERROR-2021/11/05 11:35:46,214-org.apache.flink.runtime.rest.handler.AbstractHandler.handleException(AbstractHandler.java:219)-219-Unhandled exception.
org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
-ERROR-2021/11/05 11:36:00,657-org.apache.flink.runtime.rest.handler.taskmanager.AbstractTaskManagerFileHandler.lambda$respondToRequest$1(AbstractTaskManagerFileHandler.java:136)-136-Failed to transfer file from TaskExecutor fa3d5091-a801-4fe1-80f7-2725b020afc8.
java.util.concurrent.CompletionException: org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniAccept(CompletableFuture.java:661)
	at java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:646)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)
	at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.lambda$invokeRpc$0(AkkaInvocationHandler.java:227)
	at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)
	at org.apache.flink.runtime.concurrent.FutureUtils$1.onComplete(FutureUtils.java:890)
	at akka.dispatch.OnComplete.internal(Future.scala:263)
	at akka.dispatch.OnComplete.internal(Future.scala:261)
	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:191)
	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:188)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)
	at org.apache.flink.runtime.concurrent.Executors$DirectExecutionContext.execute(Executors.java:74)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:44)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:252)
	at akka.pattern.PromiseActorRef.$bang(AskSupport.scala:572)
	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:23)
	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:21)
	at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:436)
	at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:435)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)
	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	... 4 more
-ERROR-2021/11/05 11:36:00,659-org.apache.flink.runtime.rest.handler.AbstractHandler.handleException(AbstractHandler.java:219)-219-Unhandled exception.
org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
-ERROR-2021/11/05 11:36:01,777-org.apache.flink.runtime.rest.handler.taskmanager.AbstractTaskManagerFileHandler.lambda$respondToRequest$1(AbstractTaskManagerFileHandler.java:136)-136-Failed to transfer file from TaskExecutor fa3d5091-a801-4fe1-80f7-2725b020afc8.
java.util.concurrent.CompletionException: org.apache.flink.util.FlinkException: The file STDOUT is not available on the TaskExecutor.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniAccept(CompletableFuture.java:661)
	at java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:646)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)
	at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.lambda$invokeRpc$0(AkkaInvocationHandler.java:227)
	at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)
	at org.apache.flink.runtime.concurrent.FutureUtils$1.onComplete(FutureUtils.java:890)
	at akka.dispatch.OnComplete.internal(Future.scala:263)
	at akka.dispatch.OnComplete.internal(Future.scala:261)
	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:191)
	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:188)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)
	at org.apache.flink.runtime.concurrent.Executors$DirectExecutionContext.execute(Executors.java:74)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:44)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:252)
	at akka.pattern.PromiseActorRef.$bang(AskSupport.scala:572)
	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:23)
	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:21)
	at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:436)
	at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:435)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)
	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: org.apache.flink.util.FlinkException: The file STDOUT is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	... 4 more
-ERROR-2021/11/05 11:36:01,779-org.apache.flink.runtime.rest.handler.AbstractHandler.handleException(AbstractHandler.java:219)-219-Unhandled exception.
org.apache.flink.util.FlinkException: The file STDOUT is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
-ERROR-2021/11/05 11:47:15,610-org.apache.flink.runtime.rest.handler.taskmanager.AbstractTaskManagerFileHandler.lambda$respondToRequest$1(AbstractTaskManagerFileHandler.java:136)-136-Failed to transfer file from TaskExecutor fa3d5091-a801-4fe1-80f7-2725b020afc8.
java.util.concurrent.CompletionException: org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniAccept(CompletableFuture.java:661)
	at java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:646)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)
	at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.lambda$invokeRpc$0(AkkaInvocationHandler.java:227)
	at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)
	at org.apache.flink.runtime.concurrent.FutureUtils$1.onComplete(FutureUtils.java:890)
	at akka.dispatch.OnComplete.internal(Future.scala:263)
	at akka.dispatch.OnComplete.internal(Future.scala:261)
	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:191)
	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:188)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)
	at org.apache.flink.runtime.concurrent.Executors$DirectExecutionContext.execute(Executors.java:74)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:44)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:252)
	at akka.pattern.PromiseActorRef.$bang(AskSupport.scala:572)
	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:23)
	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:21)
	at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:436)
	at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:435)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)
	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91)
	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	... 4 more
-ERROR-2021/11/05 11:47:15,614-org.apache.flink.runtime.rest.handler.AbstractHandler.handleException(AbstractHandler.java:219)-219-Unhandled exception.
org.apache.flink.util.FlinkException: The file LOG is not available on the TaskExecutor.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByFilePath(TaskExecutor.java:1747)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.requestFileUploadByType(TaskExecutor.java:1006)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
-ERROR-2021/11/05 11:47:23,762-org.apache.flink.runtime.rest.handler.AbstractHandler.handleException(AbstractHandler.java:210)-210-Exception occurred in REST handler: Job eff4ca8d3c29e541ce43aa1f922f9f25 not found
-ERROR-2021/11/05 11:47:26,754-org.apache.flink.runtime.rest.handler.AbstractHandler.handleException(AbstractHandler.java:210)-210-Exception occurred in REST handler: Job eff4ca8d3c29e541ce43aa1f922f9f25 not found
-INFO-2021/11/05 11:49:12,218-org.apache.flink.runtime.blob.AbstractBlobCache.close(AbstractBlobCache.java:251)-251-Shutting down BLOB cache
-INFO-2021/11/05 11:49:12,218-org.apache.flink.runtime.blob.AbstractBlobCache.close(AbstractBlobCache.java:251)-251-Shutting down BLOB cache
-INFO-2021/11/05 11:49:12,219-org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager.shutdown(TaskExecutorLocalStateStoresManager.java:213)-213-Shutting down TaskExecutorLocalStateStoresManager.
-INFO-2021/11/05 11:49:12,233-org.apache.flink.runtime.io.disk.FileChannelManagerImpl.lambda$getFileCloser$0(FileChannelManagerImpl.java:146)-146-FileChannelManager removed spill file directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-io-12cec0a4-beaf-438d-b890-193eb26fcbbb
-INFO-2021/11/05 11:49:12,234-org.apache.flink.runtime.filecache.FileCache.shutdown(FileCache.java:153)-153-removed file cache directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-dist-cache-26a1315d-bd0c-4722-9f48-e190ba69eaf0
-INFO-2021/11/05 11:49:12,236-org.apache.flink.runtime.blob.BlobServer.close(BlobServer.java:348)-348-Stopped BLOB server at 0.0.0.0:63728
-INFO-2021/11/05 11:49:12,237-org.apache.flink.runtime.io.disk.FileChannelManagerImpl.lambda$getFileCloser$0(FileChannelManagerImpl.java:146)-146-FileChannelManager removed spill file directory /var/folders/vn/rtfc23v97lzgw6cs_1xtn7pc0000gn/T/flink-netty-shuffle-1d22b6af-5c03-4d80-bf49-544d343e42d0
-INFO-2021/11/05 13:49:16,124-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 13:49:16,273-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 13:49:16,273-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 13:54:27,911-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 13:54:28,037-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 13:54:28,038-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 13:54:57,847-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 13:54:57,971-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 13:54:57,971-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 13:55:17,099-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 13:55:17,235-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 13:55:17,235-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 13:58:17,924-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 13:58:18,048-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 13:58:18,049-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 14:46:00,791-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 14:46:00,909-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 14:46:00,909-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 15:15:10,502-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 15:15:10,697-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 15:15:10,698-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 15:18:53,499-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 15:18:53,643-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 15:18:53,643-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 15:26:07,869-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 15:26:08,082-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 15:26:08,084-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 15:27:32,279-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 15:27:32,392-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 15:27:32,392-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 15:28:18,226-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 15:28:18,343-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 15:28:18,344-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 16:03:57,996-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 16:03:58,115-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 16:03:58,116-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 16:05:04,050-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 16:05:04,174-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 16:05:04,174-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
-INFO-2021/11/05 16:11:54,488-org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:223)-223-ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.0.12.253:18108]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

-INFO-2021/11/05 16:11:54,642-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:83)-83-Kafka version : 0.11.0.1
-INFO-2021/11/05 16:11:54,642-org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:84)-84-Kafka commitId : c2a0d5f9b1f45bf5
